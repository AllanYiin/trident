<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>trident.backend.pytorch_backend &#8212; trident 0.7.5 documentation</title>

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/material-icons.css" />
    <link rel="stylesheet" href="../../../_static/notosanscjkjp.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/roboto.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/material-design-lite-1.3.0/material.deep_orange-indigo.min.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../_static/sphinx_materialdesign_theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <!-- Title -->
        <span class="mdl-layout-title">
            <a class="brand" href="../../../index.html">
                <img class="logo" src="../../../_static/trident_logo.png" alt="trident"/>
            </a>
        </span>
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="../../index.html">Module code</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active">trident.backend.pytorch_backend</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../../../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
            <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          <a  class="mdl-navigation__link" href="../../../index.html">
                  <i class="material-icons navigation-link-icon">home</i>
                  Home
              </a>
          
              <a  class="mdl-navigation__link" href="http://example.com">
                  <i class="material-icons navigation-link-icon">launch</i>
                  ExternalLink
              </a>
          
              <a  class="mdl-navigation__link" href="http://example.com">
                  
                  NoIconLink
              </a>
          
              <a  class="mdl-navigation__link" href="https://github.com/AllanYiin/trident">
                  <i class="material-icons navigation-link-icon">link</i>
                  GitHub
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../../../index.html">
              <img class="logo" src="../../../_static/trident_logo.png" alt="trident"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
        <!-- Local TOC -->
        <nav class="mdl-navigation"></nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">
<header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../../../index.html">
              <img class="logo" src="../../../_static/trident_logo.png" alt="trident"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
        <!-- Local TOC -->
        <nav class="mdl-navigation"></nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content">
        
  <h1>Source code for trident.backend.pytorch_backend</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">builtins</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">gc</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">import</span> <span class="nn">operator</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">uuid</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">abc</span>
<span class="kn">from</span> <span class="nn">types</span> <span class="kn">import</span> <span class="n">MethodType</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span><span class="n">Iterator</span><span class="p">,</span><span class="n">Mapping</span><span class="p">,</span> <span class="n">TypeVar</span><span class="p">,</span><span class="n">overload</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">_pickle</span> <span class="k">as</span> <span class="nn">pickle</span>
<span class="k">except</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">islice</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="kn">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.onnx</span>
<span class="kn">import</span> <span class="nn">torch.utils.hooks</span> <span class="k">as</span> <span class="nn">hooks</span>
<span class="kn">from</span> <span class="nn">torch.utils.hooks</span> <span class="kn">import</span> <span class="n">RemovableHandle</span>
<span class="kn">from</span> <span class="nn">torch._jit_internal</span> <span class="kn">import</span> <span class="n">_copy_to_script_wrapper</span>
<span class="kn">from</span> <span class="nn">torch.nn.parameter</span> <span class="kn">import</span> <span class="n">Parameter</span>
<span class="kn">from</span> <span class="nn">trident.backend</span> <span class="kn">import</span> <span class="n">common</span>
<span class="kn">from</span> <span class="nn">trident.backend.common</span> <span class="kn">import</span> <span class="n">to_list</span><span class="p">,</span> <span class="n">addindent</span><span class="p">,</span> <span class="n">camel2snake</span><span class="p">,</span> <span class="n">unpack_singleton</span><span class="p">,</span> <span class="n">enforce_singleton</span><span class="p">,</span> <span class="n">OrderedDict</span><span class="p">,</span> <span class="n">get_session</span><span class="p">,</span> <span class="n">set_session</span><span class="p">,</span> <span class="n">get_session_value</span><span class="p">,</span> <span class="n">PrintException</span><span class="p">,</span> <span class="n">Signature</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">,</span> <span class="n">get_args_spec</span><span class="p">,</span><span class="n">is_instance</span>
<span class="kn">from</span> <span class="nn">trident.backend.tensorspec</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">trident.backend</span> <span class="kn">import</span> <span class="n">iteration_tools</span>
<span class="kn">from</span> <span class="nn">trident.backend.pytorch_ops</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">trident.backend</span> <span class="kn">import</span> <span class="n">pytorch_ops</span> <span class="k">as</span> <span class="n">tops</span>
<span class="kn">from</span> <span class="nn">trident.backend</span> <span class="kn">import</span> <span class="n">dtype</span>
<span class="kn">from</span> <span class="nn">trident</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">trident.context</span> <span class="kn">import</span> <span class="n">split_path</span><span class="p">,</span> <span class="n">make_dir_if_need</span><span class="p">,</span> <span class="n">sanitize_path</span>


<span class="n">ctx</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">_context</span><span class="p">()</span>
<span class="n">_backend</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">get_backend</span><span class="p">()</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;get_device&#39;</span><span class="p">,</span> <span class="s1">&#39;set_device&#39;</span><span class="p">,</span> <span class="s1">&#39;Layer&#39;</span><span class="p">,</span> <span class="s1">&#39;Sequential&#39;</span><span class="p">,</span> <span class="s1">&#39;ModuleList&#39;</span><span class="p">,</span> <span class="s1">&#39;Parameter&#39;</span><span class="p">,</span> <span class="s1">&#39;ModuleDict&#39;</span><span class="p">,</span> <span class="s1">&#39;print_network&#39;</span><span class="p">,</span> <span class="s1">&#39;summary&#39;</span><span class="p">,</span> <span class="s1">&#39;load&#39;</span><span class="p">,</span> <span class="s1">&#39;save&#39;</span><span class="p">,</span> <span class="s1">&#39;Combine&#39;</span><span class="p">,</span>
           <span class="s1">&#39;try_map_args_and_call&#39;</span><span class="p">,</span>
           <span class="s1">&#39;print_mem_stack&#39;</span><span class="p">,</span>
           <span class="s1">&#39;normalize_padding&#39;</span><span class="p">,</span> <span class="s1">&#39;fix_layer&#39;</span><span class="p">,</span> <span class="s1">&#39;DTYPE_MAPPING&#39;</span><span class="p">,</span><span class="s1">&#39;fix_pytorch_module&#39;</span><span class="p">]</span>

<span class="n">_FUN_NAMES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">,</span> <span class="n">tops</span><span class="o">.</span><span class="n">equal</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">target_fun_name</span><span class="p">,</span> <span class="n">source_fun</span> <span class="ow">in</span> <span class="n">_FUN_NAMES</span><span class="p">:</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">target_fun_name</span><span class="p">,</span> <span class="n">source_fun</span><span class="p">)</span>

<span class="n">version</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span>
<span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Pytorch version:</span><span class="si">{0}</span><span class="s1">.</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">version</span><span class="p">))</span>

<span class="n">pt_version</span> <span class="o">=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">vstring</span><span class="o">=</span><span class="n">version</span><span class="p">)</span>
<span class="n">base_version</span> <span class="o">=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">vstring</span><span class="o">=</span><span class="s1">&#39;1.4.0&#39;</span><span class="p">)</span>
<span class="n">amp_version</span> <span class="o">=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">vstring</span><span class="o">=</span><span class="s1">&#39;1.6.0&#39;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">pt_version</span><span class="o">.</span><span class="n">version</span> <span class="o">&lt;</span> <span class="n">base_version</span><span class="o">.</span><span class="n">version</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Not support Pytorch older then version 1.4&#39;</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">pt_version</span><span class="o">.</span><span class="n">version</span> <span class="o">&gt;=</span> <span class="n">amp_version</span><span class="o">.</span><span class="n">version</span><span class="p">:</span>
    <span class="n">set_session</span><span class="p">(</span><span class="s1">&#39;amp_available&#39;</span><span class="p">,</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">pt_version</span> <span class="o">&gt;=</span> <span class="n">amp_version</span> <span class="k">else</span> <span class="kc">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">get_session_value</span><span class="p">(</span><span class="s1">&#39;amp_available&#39;</span><span class="p">):</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Automatic Mixed Precision Support:</span><span class="si">{0}</span><span class="s1">.</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="kc">True</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Automatic Mixed Precision Support:</span><span class="si">{0}</span><span class="s1">.</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="kc">False</span><span class="p">))</span>

<span class="n">DTYPE_MAPPING</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span> <span class="n">dtype</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">:</span> <span class="n">dtype</span><span class="o">.</span><span class="n">int8</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">int16</span><span class="p">:</span> <span class="n">dtype</span><span class="o">.</span><span class="n">int16</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">:</span> <span class="n">dtype</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">:</span> <span class="n">dtype</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span> <span class="n">dtype</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">:</span> <span class="n">dtype</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span> <span class="n">dtype</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span> <span class="n">dtype</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">complex64</span><span class="p">:</span> <span class="n">dtype</span><span class="o">.</span><span class="n">complex64</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">complex128</span><span class="p">:</span> <span class="n">dtype</span><span class="o">.</span><span class="n">complex128</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cfloat</span><span class="p">:</span> <span class="n">dtype</span><span class="o">.</span><span class="n">cfloat</span>
<span class="p">}</span>


<div class="viewcode-block" id="get_device"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.get_device">[docs]</a><span class="k">def</span> <span class="nf">get_device</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;get current device</span>

<span class="sd">    Returns: device string (&#39;cpu&#39;, &#39;cuda)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">ctx</span><span class="o">.</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">set_device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;xpu&#39;</span> <span class="k">if</span> <span class="n">is_tpu_available</span><span class="p">()</span> <span class="k">else</span>  <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">get_session</span><span class="p">()</span><span class="o">.</span><span class="n">device</span></div>


<div class="viewcode-block" id="set_device"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.set_device">[docs]</a><span class="k">def</span> <span class="nf">set_device</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

    <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">is_gpu_available</span><span class="p">():</span>
            <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span>
        <span class="k">elif</span> <span class="n">is_tpu_available</span><span class="p">():</span>
            <span class="n">device</span><span class="o">=</span><span class="s1">&#39;xpu&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;gpu&#39;</span><span class="p">,</span> <span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Gpu is not available...&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="s1">&#39;xpu&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_tpu_available</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Tpu is not available...&#39;</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">device_</span><span class="o">=</span><span class="n">device</span>
        <span class="k">if</span> <span class="n">device</span><span class="o">==</span><span class="s1">&#39;xpu&#39;</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">torch_xla.core.xla_model</span> <span class="k">as</span> <span class="nn">xm</span>
            <span class="n">device_</span> <span class="o">=</span> <span class="n">xm</span><span class="o">.</span><span class="n">xla_device</span><span class="p">()</span>
        <span class="n">set_session</span><span class="p">(</span><span class="s1">&#39;device&#39;</span><span class="p">,</span> <span class="n">device_</span><span class="p">)</span>

        <span class="n">gcitems</span> <span class="o">=</span> <span class="n">gc</span><span class="o">.</span><span class="n">get_objects</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gcitems</span><span class="p">)):</span>
            <span class="n">obj</span> <span class="o">=</span> <span class="n">gcitems</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="p">:</span>
                    <span class="n">obj</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device_</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
                    <span class="n">obj</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device_</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">pass</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span></div>


<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">get_device</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_DEVICE_ORDER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;PCI_BUS_ID&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span>



<div class="viewcode-block" id="load"><a class="viewcode-back" href="../../../trident.models.html#trident.backend.pytorch_backend.load">[docs]</a><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        f: a file-like object (has to implement :meth:`read`, :meth`readline`, :meth`tell`, and :meth`seek`),</span>
<span class="sd">            or a string or os.PathLike object containing a file name</span>

<span class="sd">    Returns:</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">item</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="n">item</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">item</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">get_device</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">item</span></div>


<div class="viewcode-block" id="save"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.save">[docs]</a><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">is_compressed</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        obj ():</span>
<span class="sd">        f: a file-like object (has to implement write and flush) or a string or</span>
<span class="sd">           os.PathLike object containing a file name</span>
<span class="sd">        is_compressed ():</span>

<span class="sd">    Returns:</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">pickle_module</span><span class="o">=</span><span class="n">pickle</span><span class="p">,</span> <span class="n">_use_new_zipfile_serialization</span><span class="o">=</span><span class="n">is_compressed</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">True</span></div>


<span class="k">def</span> <span class="nf">reset_name</span><span class="p">(</span><span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">prefix_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">get_uid</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">seq</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">prefix</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">_uid_prefixs</span> <span class="ow">or</span> <span class="n">seq</span> <span class="o">&lt;</span> <span class="n">module</span><span class="o">.</span><span class="n">_uid_prefixs</span><span class="p">[</span><span class="n">prefix</span><span class="p">]:</span>
            <span class="n">module</span><span class="o">.</span><span class="n">_uid_prefixs</span><span class="p">[</span><span class="n">prefix</span><span class="p">]</span> <span class="o">=</span> <span class="n">seq</span>
        <span class="k">return</span> <span class="n">module</span><span class="o">.</span><span class="n">_uid_prefixs</span><span class="p">[</span><span class="n">prefix</span><span class="p">]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;_uid_prefixs&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">prefix_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">module</span><span class="o">.</span><span class="n">_uid_prefixs</span> <span class="o">=</span> <span class="n">prefix_dict</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;default_name&#39;</span><span class="p">):</span>
        <span class="n">module</span><span class="o">.</span><span class="n">default_name</span> <span class="o">=</span> <span class="n">camel2snake</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">get_global_uid</span><span class="p">(</span><span class="n">camel2snake</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)))</span>
    <span class="n">prefix</span><span class="p">,</span> <span class="n">seq</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">default_name</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># if &#39;_&#39; in module.default_name else</span>
    <span class="n">seq</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span>
    <span class="n">module</span><span class="o">.</span><span class="n">default_name</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">seq</span> <span class="o">-</span> <span class="n">get_uid</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">seq</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">module</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">_name</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;_name&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">module</span><span class="o">.</span><span class="n">default_name</span>


<span class="n">_UID_PREFIX</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_global_uid</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="n">_UID_PREFIX</span><span class="p">[</span><span class="n">prefix</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">_UID_PREFIX</span><span class="p">[</span><span class="n">prefix</span><span class="p">]</span>


<span class="n">_grad_t</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]</span>
<span class="c1"># See https://mypy.readthedocs.io/en/latest/generics.html#generic-methods-and-generic-self for the use</span>
<span class="c1"># of `T` to annotate `self`. Many methods of `Module` return `self` and we want those return values to be</span>
<span class="c1"># the type of the subclass, not the looser type of `Module`.</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="s1">&#39;Module&#39;</span><span class="p">)</span>

<span class="sa">r</span><span class="sd">&quot;&quot;&quot;This tracks hooks common to all modules that are executed before/after</span>
<span class="sd">calling forward and backward. This is global state used for debugging/profiling</span>
<span class="sd">purposes&quot;&quot;&quot;</span>
<span class="n">_global_backward_hooks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
<span class="n">_global_forward_pre_hooks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
<span class="n">_global_forward_hooks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">register_module_forward_pre_hook</span><span class="p">(</span><span class="n">hook</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">RemovableHandle</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registers a forward pre-hook common to all modules.</span>

<span class="sd">    warning ::</span>

<span class="sd">        This adds global state to the `nn.module` module,</span>
<span class="sd">        and it is only intended for debugging/profiling purposes.</span>

<span class="sd">    The hook will be called every time before :func:`forward` is invoked.</span>
<span class="sd">    It should have the following signature::</span>

<span class="sd">        hook(module, input) -&gt; None or modified input</span>

<span class="sd">    The input contains only the positional arguments given to the module.</span>
<span class="sd">    Keyword arguments won&#39;t be passed to the hooks and only to the ``forward``.</span>
<span class="sd">    The hook can modify the input. User can either return a tuple or a</span>
<span class="sd">    single modified value in the hook. We will wrap the value into a tuple</span>
<span class="sd">    if a single value is returned(unless that value is already a tuple).</span>

<span class="sd">    This hook has precedence over the specific module hooks registered with</span>
<span class="sd">    ``register_forward_pre_hook``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`torch.utils.hooks.RemovableHandle`:</span>
<span class="sd">            a handle that can be used to remove the added hook by calling</span>
<span class="sd">            ``handle.remove()``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">hooks</span><span class="o">.</span><span class="n">RemovableHandle</span><span class="p">(</span><span class="n">_global_forward_pre_hooks</span><span class="p">)</span>
    <span class="n">_global_forward_pre_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>
    <span class="k">return</span> <span class="n">handle</span>


<span class="k">def</span> <span class="nf">register_module_forward_hook</span><span class="p">(</span><span class="n">hook</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">RemovableHandle</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registers a global forward hook for all the modules</span>

<span class="sd">    warning ::</span>

<span class="sd">        This adds global state to the `nn.module` module,</span>
<span class="sd">        and it is only intended for debugging/profiling purposes.</span>

<span class="sd">    The hook will be called every time after :func:`forward` has computed an output.</span>
<span class="sd">    It should have the following signature::</span>

<span class="sd">        hook(module, input, output) -&gt; None or modified output</span>

<span class="sd">    The input contains only the positional arguments given to the module.</span>
<span class="sd">    Keyword arguments won&#39;t be passed to the hooks and only to the ``forward``.</span>
<span class="sd">    The hook can modify the output. It can modify the input inplace, but</span>
<span class="sd">    it will not have effect on forward since this is called after</span>
<span class="sd">    :func:`forward` is called.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`torch.utils.hooks.RemovableHandle`:</span>
<span class="sd">            a handle that can be used to remove the added hook by calling</span>
<span class="sd">            ``handle.remove()``</span>

<span class="sd">    This hook will be executed before specific module hooks registered with</span>
<span class="sd">    ``register_forward_hook``.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">hooks</span><span class="o">.</span><span class="n">RemovableHandle</span><span class="p">(</span><span class="n">_global_forward_hooks</span><span class="p">)</span>
    <span class="n">_global_forward_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>
    <span class="k">return</span> <span class="n">handle</span>


<span class="k">def</span> <span class="nf">register_module_backward_hook</span><span class="p">(</span>
        <span class="n">hook</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="s1">&#39;Module&#39;</span><span class="p">,</span> <span class="n">_grad_t</span><span class="p">,</span> <span class="n">_grad_t</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RemovableHandle</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registers a backward hook common to all the modules.</span>

<span class="sd">    warning ::</span>
<span class="sd">        This adds global state to the `nn.module` module,</span>
<span class="sd">        and it is only intended for debugging/profiling purposes.</span>

<span class="sd">        The current implementation will not have the presented behavior</span>
<span class="sd">        for complex :class:`Module` that perform many operations.</span>
<span class="sd">        In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only</span>
<span class="sd">        contain the gradients for a subset of the inputs and outputs.</span>
<span class="sd">        For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`</span>
<span class="sd">        directly on a specific input or output to get the required gradients.</span>

<span class="sd">    The hook will be called every time the gradients with respect to module</span>
<span class="sd">    inputs are computed. The hook should have the following signature::</span>

<span class="sd">        hook(module, grad_input, grad_output) -&gt; Tensor or None</span>

<span class="sd">    The :attr:`grad_input` and :attr:`grad_output` may be tuples if the</span>
<span class="sd">    module has multiple inputs or outputs. The hook should not modify its</span>
<span class="sd">    arguments, but it can optionally return a new gradient with respect to</span>
<span class="sd">    input that will be used in place of :attr:`grad_input` in subsequent</span>
<span class="sd">    computations. :attr:`grad_input` will only correspond to the inputs given</span>
<span class="sd">    as positional arguments.</span>

<span class="sd">    Global hooks are called before hooks registered with `register_backward_hook`</span>

<span class="sd">    Returns:</span>
<span class="sd">        :class:`torch.utils.hooks.RemovableHandle`:</span>
<span class="sd">            a handle that can be used to remove the added hook by calling</span>
<span class="sd">            ``handle.remove()``</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">handle</span> <span class="o">=</span> <span class="n">hooks</span><span class="o">.</span><span class="n">RemovableHandle</span><span class="p">(</span><span class="n">_global_backward_hooks</span><span class="p">)</span>
    <span class="n">_global_backward_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>
    <span class="k">return</span> <span class="n">handle</span>


<div class="viewcode-block" id="Parameter"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Parameter">[docs]</a><span class="k">class</span> <span class="nc">Parameter</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">inst</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">trainable</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">inst</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">trainable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">requires_grad</span>

    <span class="nd">@trainable</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">trainable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">value</span></div>


<div class="viewcode-block" id="Layer"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer">[docs]</a><span class="k">class</span> <span class="nc">Layer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Trident extened pytorch nn.Module as base layer class.</span>

<span class="sd">    Your models should also subclass of this class.</span>
<span class="sd">    Layer contains :</span>
<span class="sd">        modules: another child layer(module) in it.</span>
<span class="sd">        parameters: the trainable parameters in the layer.</span>
<span class="sd">        buffers: the other non_trainable tensor in the layer.</span>

<span class="sd">    Attributes :</span>
<span class="sd">        training (bool): If True, means in the training phase, else in the evaluation phase.</span>
<span class="sd">        rank (int): The number of the spatial related axes.</span>
<span class="sd">        _modules (OrderedDict) : storage of all the submodules.</span>

<span class="sd">        _parameters (OrderedDict) : storage of all the tranable weights.</span>

<span class="sd">        _buffers (OrderedDict) : storage of all the non-trainable tensor.</span>

<span class="sd">        _forward_hooks (OrderedDict) : storage of all the hooks triggered before the forward execution.</span>

<span class="sd">        _forward_pre_hooks (OrderedDict) : storage of all the hooks triggered  after the forward execution.</span>

<span class="sd">        _state_dict_hooks (OrderedDict) : storage of all the hooks triggered  when state_dict generating  execution.</span>

<span class="sd">        _load_state_dict_pre_hooks (OrderedDict) : storage of all the hooks triggered  when loading state_dict   execution.</span>


<span class="sd">        input_filters (int): input channels</span>

<span class="sd">        signature (int): the function signature of this layer.</span>

<span class="sd">        default_name: default_name is the same concept as in keras, it comes from class name with sequence number.</span>

<span class="sd">        relative_name:relative_name is the same concept as named_modules in pytorch. But in pytorch, you need to get the name from generator enumeration. In trident,</span>
<span class="sd">        you can access the relative name  with this attribute.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_version</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">_is_full_backward_hook</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keep_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str) :name of the layer.</span>
<span class="sd">            keep_output (bool) :whether you need to kept output tensor in execution time.</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filter_index</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_sequence</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;in_sequence&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_sequence</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">filter_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_built</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;rank&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_non_persistent_buffers_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">uuid</span> <span class="o">=</span> <span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">()</span><span class="o">.</span><span class="n">node</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_uid_prefixs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_root</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">prefix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_name</span> <span class="o">=</span> <span class="n">camel2snake</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">get_global_uid</span><span class="p">(</span><span class="n">camel2snake</span><span class="p">(</span><span class="n">prefix</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relative_name</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
        <span class="n">reset_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uid_prefixs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorShape</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorShape</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_filters</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">keep_output</span> <span class="o">=</span> <span class="n">keep_output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;_output_tensor&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">=</span><span class="n">get_signature</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">get_device</span><span class="p">()</span>


        <span class="bp">self</span><span class="o">.</span><span class="n">dump_patches</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Trick mypy into not applying contravariance rules to input by defining</span>
    <span class="c1"># forward as a value, rather than a function.  See also</span>
    <span class="c1"># https://github.com/python/mypy/issues/8795</span>
    <span class="k">def</span> <span class="nf">_forward_unimplemented</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="nb">input</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Defines the computation performed at every call.</span>

<span class="sd">    Should be overridden by all subclasses.</span>

<span class="sd">    .. note::</span>
<span class="sd">        Although the recipe for forward pass needs to be defined within</span>
<span class="sd">        this function, one should call the :class:`Module` instance afterwards</span>
<span class="sd">        instead of this since the former takes care of running the</span>
<span class="sd">        registered hooks while the latter silently ignores them.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">forward</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="n">_forward_unimplemented</span>

<div class="viewcode-block" id="Layer.get_root"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer.get_root">[docs]</a>    <span class="k">def</span> <span class="nf">get_root</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_nodes&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">is_root</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_root</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">is_root</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">node</span>
            <span class="k">return</span> <span class="bp">self</span></div>

    <span class="c1"># def forward(self, *input,**kwargs):</span>
    <span class="c1">#     r&quot;&quot;&quot;Defines the computation performed at every call.</span>
    <span class="c1">#</span>
    <span class="c1">#     Should be overridden by all subclasses.</span>
    <span class="c1">#</span>
    <span class="c1">#     .. note::</span>
    <span class="c1">#         Although the recipe for forward pass needs to be defined within</span>
    <span class="c1">#         this function, one should call the :class:`Module` instance afterwards</span>
    <span class="c1">#         instead of this since the former takes care of running the</span>
    <span class="c1">#         registered hooks while the latter silently ignores them.</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#     raise NotImplementedError</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;If not assign name , it will return the default_name&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">relative_name</span>

    <span class="nd">@name</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">value</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The whole tree structured OrderedDict { uuid : module } , for module to access any node in these structures, ex. Shortcut&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span>

    <span class="nd">@nodes</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span> <span class="o">!=</span> <span class="n">value</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">for</span> <span class="n">mod</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
                <span class="n">mod</span><span class="o">.</span><span class="n">_nodes</span> <span class="o">=</span> <span class="n">value</span>

<div class="viewcode-block" id="Layer.add_module"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer.add_module">[docs]</a>    <span class="k">def</span> <span class="nf">add_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adds a child module to the current module.</span>

<span class="sd">        The module can be accessed as an attribute using the given name.</span>
<span class="sd">        1) add module as child</span>

<span class="sd">        2) generate default_name and relative_name</span>

<span class="sd">        3) update the nodes</span>

<span class="sd">        Args:</span>
<span class="sd">            name (string): name of the child module. The child module can be</span>
<span class="sd">                accessed from this module using the given name</span>
<span class="sd">            module (Module): child module to be added to the module.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">Layer</span><span class="p">))</span> <span class="ow">and</span> <span class="n">module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> is not a Module subclass&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">(</span><span class="n">module</span><span class="p">)))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">Combine</span><span class="p">))</span> <span class="ow">and</span> <span class="n">module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> cannot be added&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">(</span><span class="n">module</span><span class="p">)))</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_six</span><span class="o">.</span><span class="n">string_classes</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;module name should be a string. Got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">(</span><span class="n">name</span><span class="p">)))</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;attribute &#39;</span><span class="si">{}</span><span class="s2">&#39; already exists&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
        <span class="k">elif</span> <span class="s1">&#39;.&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
            <span class="c1"># name=name.replace(&#39;.&#39;,&#39;_&#39;)</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;module name can&#39;t contain </span><span class="se">\&quot;</span><span class="s2">.</span><span class="se">\&quot;</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;module name can&#39;t be empty string </span><span class="se">\&quot;\&quot;</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">module</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">([(</span><span class="n">mod</span><span class="o">.</span><span class="n">uuid</span><span class="p">,</span> <span class="n">mod</span><span class="p">)</span> <span class="k">for</span> <span class="n">mod</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">())</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">Layer</span><span class="p">)])</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">Layer</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
                <span class="n">mod</span><span class="o">.</span><span class="n">nodes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span>
                <span class="n">mod</span><span class="o">.</span><span class="n">is_root</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">mod</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>
                <span class="n">mod</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
                <span class="n">reset_name</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uid_prefixs</span><span class="p">)</span>
                <span class="n">mod</span><span class="o">.</span><span class="n">relative_name</span> <span class="o">=</span> <span class="n">name</span> <span class="k">if</span> <span class="n">mod</span><span class="o">.</span><span class="n">relative_name</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span> <span class="k">else</span> <span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span> <span class="o">+</span> <span class="n">mod</span><span class="o">.</span><span class="n">relative_name</span></div>

<div class="viewcode-block" id="Layer.add"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer.add">[docs]</a>    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Simplified add_module</span>

<span class="sd">        Use the count of child modules as the default name.</span>

<span class="sd">        Args:</span>
<span class="sd">            module (Module): child module to be added to the module.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">module</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;module  can&#39;t be None&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">Layer</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">)),</span> <span class="n">module</span><span class="p">)</span>  <span class="c1"># self.nodes = nodes  # for mod in self.modules():  #     mod.nodes = nodes</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Not valid module&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Layer.build"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer.build">[docs]</a>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">input_shape</span><span class="p">:</span> <span class="n">TensorShape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Do the shape inference and initialize weights and bias.</span>

<span class="sd">        `build&#39; is a key method in trident, you can use  property `built&#39; to check whether the layer do the build process.</span>
<span class="sd">        In &#39;build&#39; , we need to put all the logics about  how to comfirm the shape of outputs, weights and bias according to the coming input tensor.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_shape (TensorShape):  the shape representation exclude the batch axis.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="Layer.rebuild"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer.rebuild">[docs]</a>    <span class="k">def</span> <span class="nf">rebuild</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Do the shape inference and initialize weights and bias.</span>

<span class="sd">        `build&#39; is a key method in trident, you can use  property `built&#39; to check whether the layer do the build process.</span>
<span class="sd">        In &#39;build&#39; , we need to put all the logics about  how to comfirm the shape of outputs, weights and bias according to the coming input tensor.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_shape (tensor):  the shape representation exclude the batch axis.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Your model will start to rebuild, it will cause lost all existing trainable parameters, will you want to rebuild it?&#39;</span><span class="p">)</span>
        <span class="n">ans</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;(Y/N) &lt;&lt; &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">ans</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;yes&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">]:</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">_parameters</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">module</span><span class="o">.</span><span class="n">trainable</span><span class="p">:</span>
                    <span class="n">module</span><span class="o">.</span><span class="n">_input_shape</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">module</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">module</span><span class="o">.</span><span class="n">_built</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                        <span class="n">module</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">module</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>

            <span class="n">dummay_input</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="mi">2</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">get_device</span><span class="p">())</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">dummay_input</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">trainable_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;The list of trainable variables (parameters) of the module.</span>
<span class="sd">        Parameters of this module and all its submodules are included.</span>

<span class="sd">        Notes:</span>
<span class="sd">            The list returned may contain duplicate parameters (e.g. output</span>
<span class="sd">            layer shares parameters with embeddings). For most usages, it&#39;s not</span>
<span class="sd">            necessary to ensure uniqueness.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">paras</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                <span class="n">paras</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">paras</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">non_trainable_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The list of non-trainable variables (parameters) of the module.Parameters of this module and all its submodules are included.</span>

<span class="sd">        Notes:</span>
<span class="sd">            The list returned may contain duplicate parameters (e.g. output</span>
<span class="sd">            layer shares parameters with embeddings). For most usages, it&#39;s not</span>
<span class="sd">            necessary to ensure uniqueness.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">paras</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                <span class="n">paras</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">paras</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The list of all variables (parameters) of the module.Parameters of this module and all its submodules are included.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

<div class="viewcode-block" id="Layer.get_weights"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer.get_weights">[docs]</a>    <span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The list of all numpy variables ndarray equivelent of the module.Parameters of this module and all its submodules are included.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())]</span></div>

<div class="viewcode-block" id="Layer.set_weights"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer.set_weights">[docs]</a>    <span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="n">weight_value_tuples</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">param_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">data</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">params</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">pv</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">param_values</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">pv</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Layer weight shape &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pv</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; not compatible with &#39;</span>
                                                                         <span class="s1">&#39;provided weight shape &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
            <span class="n">weight_value_tuples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">w</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">weight_value_tuples</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">data</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">trainable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">v</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">==</span> <span class="kc">False</span><span class="p">):</span>
                    <span class="k">return</span> <span class="kc">False</span>
                <span class="k">elif</span> <span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">pass</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">pass</span>
            <span class="k">return</span> <span class="kc">True</span>

    <span class="nd">@trainable</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">trainable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">para</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">para</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">!=</span> <span class="n">value</span><span class="p">):</span>
                <span class="n">para</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">value</span>
                <span class="n">n</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">para</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>
        <span class="k">if</span> <span class="n">value</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{0}</span><span class="s1"> parameters have set trainable&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{0}</span><span class="s1"> parameters have set untrainable&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_root</span> <span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">get_device</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_root</span><span class="p">()</span><span class="o">.</span><span class="n">device</span>

    <span class="nd">@device</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

<div class="viewcode-block" id="Layer.cuda"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer.cuda">[docs]</a>    <span class="k">def</span> <span class="nf">cuda</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Moves all model parameters and buffers to the GPU.</span>

<span class="sd">        This also makes associated parameters and buffers different objects. So</span>
<span class="sd">        it should be called before constructing optimizer if the module will</span>
<span class="sd">        live on GPU while being optimized.</span>

<span class="sd">        Args:</span>
<span class="sd">            device (int, optional): if specified, all parameters will be</span>
<span class="sd">                copied to that device</span>

<span class="sd">        Returns:</span>
<span class="sd">            Module: self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="p">))</span></div>

<div class="viewcode-block" id="Layer.xpu"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer.xpu">[docs]</a>    <span class="k">def</span> <span class="nf">xpu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Moves all model parameters and buffers to the XPU.</span>

<span class="sd">        This also makes associated parameters and buffers different objects. So</span>
<span class="sd">        it should be called before constructing optimizer if the module will</span>
<span class="sd">        live on XPU while being optimized.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            device (int, optional): if specified, all parameters will be</span>
<span class="sd">                copied to that device</span>

<span class="sd">        Returns:</span>
<span class="sd">            Module: self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_tpu_available</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">device</span> <span class="o">==</span> <span class="s1">&#39;xpu&#39;</span> <span class="ow">or</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
            <span class="kn">import</span> <span class="nn">torch_xla.core.xla_model</span> <span class="k">as</span> <span class="nn">xm</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">xm</span><span class="o">.</span><span class="n">xla_device</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">xpu</span><span class="p">(</span><span class="n">device</span><span class="p">))</span></div>

<div class="viewcode-block" id="Layer.cpu"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer.cpu">[docs]</a>    <span class="k">def</span> <span class="nf">cpu</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Moves all model parameters and buffers to the CPU.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Module: self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span></div>

<div class="viewcode-block" id="Layer.gpu"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer.gpu">[docs]</a>    <span class="k">def</span> <span class="nf">gpu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Moves all model parameters and buffers to the GPU.</span>

<span class="sd">            This also makes associated parameters and buffers different objects. So</span>
<span class="sd">            it should be called before constructing optimizer if the module will</span>
<span class="sd">            live on GPU while being optimized.</span>

<span class="sd">            Args:</span>
<span class="sd">                device (int, optional): if specified, all parameters will be</span>
<span class="sd">                    copied to that device</span>

<span class="sd">            Returns:</span>
<span class="sd">                Module: self</span>
<span class="sd">            &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="p">))</span></div>



    <span class="c1"># def to(self, *args, **kwargs):</span>
    <span class="c1">#     r&quot;&quot;&quot;Moves and/or casts the parameters and buffers.</span>
    <span class="c1">#</span>
    <span class="c1">#     This can be called as</span>
    <span class="c1">#</span>
    <span class="c1">#     .. function:: to(device=None, dtype=None, non_blocking=False)</span>
    <span class="c1">#</span>
    <span class="c1">#     .. function:: to(dtype, non_blocking=False)</span>
    <span class="c1">#</span>
    <span class="c1">#     .. function:: to(tensor, non_blocking=False)</span>
    <span class="c1">#</span>
    <span class="c1">#     .. function:: to(memory_format=torch.channels_last)</span>
    <span class="c1">#</span>
    <span class="c1">#     Its signature is similar to :meth:`torch.Tensor.to`, but only accepts</span>
    <span class="c1">#     floating point or complex :attr:`dtype`s. In addition, this method will</span>
    <span class="c1">#     only cast the floating point or complex parameters and buffers to :attr:`dtype`</span>
    <span class="c1">#     (if given). The integral parameters and buffers will be moved</span>
    <span class="c1">#     :attr:`device`, if that is given, but with dtypes unchanged. When</span>
    <span class="c1">#     :attr:`non_blocking` is set, it tries to convert/move asynchronously</span>
    <span class="c1">#     with respect to the host if possible, e.g., moving CPU Tensors with</span>
    <span class="c1">#     pinned memory to CUDA devices.</span>
    <span class="c1">#</span>
    <span class="c1">#     See below for examples.</span>
    <span class="c1">#</span>
    <span class="c1">#     .. note::</span>
    <span class="c1">#         This method modifies the module in-place.</span>
    <span class="c1">#</span>
    <span class="c1">#     Args:</span>
    <span class="c1">#         device (:class:`torch.device`): the desired device of the parameters</span>
    <span class="c1">#             and buffers in this module</span>
    <span class="c1">#         dtype (:class:`torch.dtype`): the desired floating point or complex dtype of</span>
    <span class="c1">#             the parameters and buffers in this module</span>
    <span class="c1">#         tensor (torch.Tensor): Tensor whose dtype and device are the desired</span>
    <span class="c1">#             dtype and device for all parameters and buffers in this module</span>
    <span class="c1">#         memory_format (:class:`torch.memory_format`): the desired memory</span>
    <span class="c1">#             format for 4D parameters and buffers in this module (keyword</span>
    <span class="c1">#             only argument)</span>
    <span class="c1">#</span>
    <span class="c1">#     Returns:</span>
    <span class="c1">#         Module: self</span>
    <span class="c1">#</span>
    <span class="c1">#     Examples::</span>
    <span class="c1">#</span>
    <span class="c1">#         &gt;&gt;&gt; linear = nn.Linear(2, 2)</span>
    <span class="c1">#         &gt;&gt;&gt; linear.weight</span>
    <span class="c1">#         Parameter containing:</span>
    <span class="c1">#         tensor([[ 0.1913, -0.3420],</span>
    <span class="c1">#                 [-0.5113, -0.2325]])</span>
    <span class="c1">#         &gt;&gt;&gt; linear.to(torch.double)</span>
    <span class="c1">#         Linear(in_features=2, out_features=2, bias=True)</span>
    <span class="c1">#         &gt;&gt;&gt; linear.weight</span>
    <span class="c1">#         Parameter containing:</span>
    <span class="c1">#         tensor([[ 0.1913, -0.3420],</span>
    <span class="c1">#                 [-0.5113, -0.2325]], dtype=torch.float64)</span>
    <span class="c1">#         &gt;&gt;&gt; gpu1 = torch.device(&quot;cuda:1&quot;)</span>
    <span class="c1">#         &gt;&gt;&gt; linear.to(gpu1, dtype=torch.half, non_blocking=True)</span>
    <span class="c1">#         Linear(in_features=2, out_features=2, bias=True)</span>
    <span class="c1">#         &gt;&gt;&gt; linear.weight</span>
    <span class="c1">#         Parameter containing:</span>
    <span class="c1">#         tensor([[ 0.1914, -0.3420],</span>
    <span class="c1">#                 [-0.5112, -0.2324]], dtype=torch.float16, device=&#39;cuda:1&#39;)</span>
    <span class="c1">#         &gt;&gt;&gt; cpu = torch.device(&quot;cpu&quot;)</span>
    <span class="c1">#         &gt;&gt;&gt; linear.to(cpu)</span>
    <span class="c1">#         Linear(in_features=2, out_features=2, bias=True)</span>
    <span class="c1">#         &gt;&gt;&gt; linear.weight</span>
    <span class="c1">#         Parameter containing:</span>
    <span class="c1">#         tensor([[ 0.1914, -0.3420],</span>
    <span class="c1">#                 [-0.5112, -0.2324]], dtype=torch.float16)</span>
    <span class="c1">#</span>
    <span class="c1">#         &gt;&gt;&gt; linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)</span>
    <span class="c1">#         &gt;&gt;&gt; linear.weight</span>
    <span class="c1">#         Parameter containing:</span>
    <span class="c1">#         tensor([[ 0.3741+0.j,  0.2382+0.j],</span>
    <span class="c1">#                 [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)</span>
    <span class="c1">#         &gt;&gt;&gt; linear(torch.ones(3, 2, dtype=torch.cdouble))</span>
    <span class="c1">#         tensor([[0.6122+0.j, 0.1150+0.j],</span>
    <span class="c1">#                 [0.6122+0.j, 0.1150+0.j],</span>
    <span class="c1">#                 [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)</span>
    <span class="c1">#</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#</span>
    <span class="c1">#     device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)</span>
    <span class="c1">#</span>
    <span class="c1">#     if dtype is not None:</span>
    <span class="c1">#         if not (dtype.is_floating_point or dtype.is_complex):</span>
    <span class="c1">#             raise TypeError(&#39;nn.Module.to only accepts floating point or complex &#39;</span>
    <span class="c1">#                             &#39;dtypes, but got desired dtype={}&#39;.format(dtype))</span>
    <span class="c1">#         if dtype.is_complex:</span>
    <span class="c1">#             warnings.warn(</span>
    <span class="c1">#                 &quot;Complex modules are a new feature under active development whose design may change, &quot;</span>
    <span class="c1">#                 &quot;and some modules might not work as expected when using complex tensors as parameters or buffers. &quot;</span>
    <span class="c1">#                 &quot;Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.md &quot;</span>
    <span class="c1">#                 &quot;if a complex module does not work as expected.&quot;)</span>
    <span class="c1">#</span>
    <span class="c1">#     def convert(t):</span>
    <span class="c1">#         if convert_to_format is not None and t.dim() in (4, 5):</span>
    <span class="c1">#             return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,</span>
    <span class="c1">#                         non_blocking, memory_format=convert_to_format)</span>
    <span class="c1">#         return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)</span>
    <span class="c1">#</span>
    <span class="c1">#     return self._apply(convert)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">built</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_built</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">input_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Shape of input tensor,not including the batch axis.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span>

    <span class="nd">@input_shape</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">input_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorShape</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Setting the input_shape, means the layer get shape information and start to do the shape inferrence &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">is_tensor</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="ow">and</span> <span class="n">value</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">value</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">,</span> <span class="p">]</span> <span class="o">+</span> <span class="n">to_list</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">value</span><span class="p">)))</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
            <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">((</span><span class="kc">None</span><span class="p">,)</span> <span class="o">+</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">([</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ndim</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">item</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">int32</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">sh</span><span class="p">)</span> <span class="k">for</span> <span class="n">sh</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">):</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_built</span> <span class="o">==</span> <span class="kc">False</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_filters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span> <span class="o">=</span> <span class="n">value</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_filters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">filter_index</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_built</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_root</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">unpack_singleton</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">value_list</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span>

    <span class="nd">@output_shape</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">is_tensor</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="ow">and</span> <span class="n">value</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">value</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">,</span> <span class="p">]</span> <span class="o">+</span> <span class="n">to_list</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">value</span><span class="p">)))</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
            <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">((</span><span class="kc">None</span><span class="p">,)</span> <span class="o">+</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">([</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ndim</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">item</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">int32</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">sh</span><span class="p">)</span> <span class="k">for</span> <span class="n">sh</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">):</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_root</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="o">=</span> <span class="n">Signature</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output&#39;</span><span class="p">)</span>

            <span class="k">elif</span> <span class="n">is_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">to_list</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">))),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">)):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;output_</span><span class="si">{0}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span> <span class="o">=</span> <span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_</span><span class="si">{0}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">signature</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">arg_spec</span> <span class="o">=</span> <span class="n">get_args_spec</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">)</span>
        <span class="n">inspect_args</span> <span class="o">=</span> <span class="p">[</span><span class="n">arg</span> <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">arg_spec</span><span class="o">.</span><span class="n">args</span><span class="p">)</span> <span class="k">if</span> <span class="n">arg</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;self&#39;</span><span class="p">,</span> <span class="s1">&#39;kwargs&#39;</span><span class="p">]]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg_spec</span><span class="o">.</span><span class="n">varargs</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">inspect_args</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">arg_spec</span><span class="o">.</span><span class="n">varargs</span><span class="p">)</span>
        <span class="n">inspect_args</span> <span class="o">=</span> <span class="n">unpack_singleton</span><span class="p">(</span><span class="n">inspect_args</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="o">=</span> <span class="n">Signature</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inspect_args</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">inspect_args</span><span class="p">]</span> <span class="o">=</span> <span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">TensorShape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">inspect_args</span><span class="p">)</span>

                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">)):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">TensorShape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;input_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">inspect_args</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">TensorShape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">)):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;output_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output_</span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inspect_args</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">key_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">inspect_args</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">inspect_args</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">value_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">key_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inspect_args</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">inspect_args</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inspect_args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">key_list</span><span class="o">.</span><span class="n">copy</span><span class="p">()):</span>
                <span class="k">if</span> <span class="n">k1</span> <span class="o">!=</span> <span class="n">k2</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">k1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">k2</span><span class="p">]</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">k2</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span>

    <span class="nd">@signature</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">signature</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="o">=</span> <span class="n">value</span>

    <span class="c1"># @property</span>
    <span class="c1"># def input(self):</span>
    <span class="c1">#     return NotImplemented</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">output</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Retrieves the output tensor(s) of a layer.</span>
<span class="sd">            for memory saving issue, we don&#39;t prefer to keep every input/output</span>
<span class="sd">            tensor in every layer.You should set self.keep_output flag to True, and then</span>
<span class="sd">            retrive the output tensor when the calll() is executing.</span>
<span class="sd">        Returns</span>
<span class="sd">            Output tensor or list of output tensors.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_output</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_tensor</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_tensor</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_tensor</span>

<div class="viewcode-block" id="Layer.reset_parameters"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer.reset_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="Layer.copy"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer.copy">[docs]</a>    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create a new FrozenDict with additional or replaced entries.&quot;&quot;&quot;</span>
        <span class="n">sig</span> <span class="o">=</span> <span class="n">get_signature</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span>
        <span class="n">_args</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">inp</span> <span class="ow">in</span> <span class="n">sig</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">key_list</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">inp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
                <span class="n">_args</span><span class="p">[</span><span class="n">inp</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">inp</span><span class="p">]</span>
        <span class="n">shadow</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)(</span><span class="o">**</span><span class="n">_args</span><span class="p">)</span>
        <span class="n">shadow</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_args</span> <span class="ow">and</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;_modules&#39;</span><span class="p">,</span> <span class="s1">&#39;_parameters&#39;</span><span class="p">,</span> <span class="s1">&#39;_buffers&#39;</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">is_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
                    <span class="n">shadow</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                                                   <span class="n">requires_grad</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">))</span> <span class="ow">or</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;_nodes&#39;</span><span class="p">]:</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="n">shadow</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="n">shadow</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
        <span class="n">shadow</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        <span class="n">shadow</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">shadow</span></div>

<div class="viewcode-block" id="Layer.save_onnx"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Layer.save_onnx">[docs]</a>    <span class="k">def</span> <span class="nf">save_onnx</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
        <span class="n">input_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">value_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">dims</span>
        <span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">_out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">folder</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">ext</span> <span class="o">=</span> <span class="n">split_path</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">filename</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="n">filename</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span>
        <span class="n">ext</span> <span class="o">=</span> <span class="s1">&#39;.onnx_&#39;</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="n">sanitize_path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">filename</span> <span class="o">+</span> <span class="n">ext</span><span class="p">))</span>
        <span class="n">make_dir_if_need</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>

        <span class="c1"># Export the model</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>  <span class="c1"># model being run</span>
                          <span class="n">x</span><span class="p">,</span>  <span class="c1"># model input (or a tuple for multiple inputs)</span>
                          <span class="n">save_path</span><span class="p">,</span>  <span class="c1"># where to save the model (can be a file or file-like object)</span>
                          <span class="n">export_params</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># store the trained parameter weights inside the model file</span>
                          <span class="n">opset_version</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span>  <span class="c1"># the ONNX version to export the model to</span>
                          <span class="n">do_constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># whether to execute constant folding for optimization</span>
                          <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">],</span>  <span class="c1"># the model&#39;s input names</span>
                          <span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">],</span>  <span class="c1"># the model&#39;s output names</span>
                          <span class="n">dynamic_axes</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;input&#39;</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">},</span>  <span class="c1"># variable lenght axes</span>
                                        <span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">}})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">shutil</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="n">save_path</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.onnx_&#39;</span><span class="p">,</span> <span class="s1">&#39;.onnx&#39;</span><span class="p">))</span>
        <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_call_impl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">forward_call</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_slow_forward</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_get_tracing_state</span><span class="p">()</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">)</span>

        <span class="c1"># Do not call functions when jit is used</span>
        <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span><span class="p">:</span>
            <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_backward_hooks</span><span class="p">()</span>

        <span class="n">is_all_numpy</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">is_built</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_built</span>

        <span class="c1"># only do in the root</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_root</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">is_all_numpy</span> <span class="o">=</span> <span class="nb">all</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">for</span> <span class="n">inp</span> <span class="ow">in</span> <span class="nb">input</span><span class="p">])</span>
                <span class="nb">input</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">get_device</span><span class="p">())</span> <span class="k">for</span> <span class="n">inp</span> <span class="ow">in</span> <span class="nb">input</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                    <span class="n">is_all_numpy</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="nb">input</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">get_device</span><span class="p">())</span>
                <span class="nb">input</span> <span class="o">=</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span>

        <span class="k">if</span> <span class="n">_global_forward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="p">(</span><span class="o">*</span><span class="n">_global_forward_pre_hooks</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                        <span class="n">result</span> <span class="o">=</span> <span class="p">(</span><span class="n">result</span><span class="p">,)</span>
                    <span class="nb">input</span> <span class="o">=</span> <span class="n">result</span>



        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_built</span><span class="p">:</span>
            <span class="n">inp</span> <span class="o">=</span> <span class="n">unpack_singleton</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">is_tensor</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
                <span class="n">shp</span> <span class="o">=</span> <span class="n">tensor_to_shape</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">need_exclude_batch_axis</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_filters</span> <span class="o">=</span> <span class="n">shp</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">filter_index</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="n">shp</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_root</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="o">=</span> <span class="n">get_signature</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">key_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">tensor_to_shape</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">need_exclude_batch_axis</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">is_singleton</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">del</span> <span class="n">inp</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">inp</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="o">*</span><span class="n">inp</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                    <span class="c1"># shp =[ tensor_to_shape(i, need_exclude_batch_axis=True,is_singleton=False) for i in inp]</span>
                    <span class="c1"># self.build(*shp)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">inp</span><span class="p">))</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;input shou be tensor or tuple of tensor&#39;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_built</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">bw_hook</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">full_backward_hooks</span><span class="p">:</span>
            <span class="n">bw_hook</span> <span class="o">=</span> <span class="n">hooks</span><span class="o">.</span><span class="n">BackwardHook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">full_backward_hooks</span><span class="p">)</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">bw_hook</span><span class="o">.</span><span class="n">setup_input_hook</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

        <span class="c1"># orig_input=[inp.copy().detach() for inp in input]</span>
        <span class="c1"># is_abnormal=any([any_abnormal_number(inp)for inp in orig_input])</span>
        <span class="c1"># if len(self.weights)&gt;0 and self.weights[0] is not None and not self.weights[0].requires_grad:</span>
        <span class="c1">#     print(self.relative_name,&#39;weights requires_grad&#39;,self.weights[0].requires_grad)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># if not is_abnormal and any([any_abnormal_number(inp)for inp in result]):</span>
        <span class="c1">#     print(&#39;abnormal_number&#39;,self.relative_name,&#39;before:&#39;,is_abnormal)</span>
        <span class="c1">#     print(&#39;orig_input&#39;,[inp[0,:] for inp in orig_input])</span>
        <span class="c1">#     print(&#39;result&#39;, [inp[0,:] for inp in result])</span>
        <span class="c1">#     print(&#39;weight&#39;,list(self.named_parameters()))</span>
        <span class="c1">#     print(&#39;activation&#39;,self.activation)</span>
        <span class="c1">#     out=forward_call(*orig_input, **kwargs)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">unpack_singleton</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>


        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;keep_output&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_output</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1"># make a op</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_output_tensor</span> <span class="o">=</span> <span class="n">result</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">is_built</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">result</span>
            <span class="k">if</span> <span class="n">is_tensor</span><span class="p">(</span><span class="n">output</span><span class="p">):</span>  <span class="c1"># one output</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="n">tensor_to_shape</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">output_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">tensor_to_shape</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">output</span> <span class="k">if</span> <span class="n">item</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))])</span>
                <span class="c1"># if not isinstance(item, (list,tuple)) lstm</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="n">unpack_singleton</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="p">(</span><span class="o">*</span><span class="n">_global_forward_hooks</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
                <span class="n">hook_result</span> <span class="o">=</span> <span class="n">hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">hook_result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="n">hook_result</span>

        <span class="k">if</span> <span class="n">bw_hook</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">bw_hook</span><span class="o">.</span><span class="n">setup_output_hook</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

        <span class="c1"># Handle the non-full backward hooks</span>
        <span class="k">if</span> <span class="n">non_full_backward_hooks</span><span class="p">:</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">result</span>
            <span class="k">while</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                    <span class="n">var</span> <span class="o">=</span> <span class="nb">next</span><span class="p">((</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">var</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">var</span> <span class="o">=</span> <span class="n">var</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">grad_fn</span> <span class="o">=</span> <span class="n">var</span><span class="o">.</span><span class="n">grad_fn</span>
            <span class="k">if</span> <span class="n">grad_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="n">non_full_backward_hooks</span><span class="p">:</span>
                    <span class="n">wrapper</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">hook</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
                    <span class="n">functools</span><span class="o">.</span><span class="n">update_wrapper</span><span class="p">(</span><span class="n">wrapper</span><span class="p">,</span> <span class="n">hook</span><span class="p">)</span>
                    <span class="n">grad_fn</span><span class="o">.</span><span class="n">register_hook</span><span class="p">(</span><span class="n">wrapper</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_warn_non_full_backward_hook</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">grad_fn</span><span class="p">)</span>


        <span class="k">if</span> <span class="n">is_all_numpy</span> <span class="o">==</span> <span class="kc">True</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">==</span> <span class="kc">False</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_root</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">is_tensor</span><span class="p">(</span><span class="n">result</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">to_numpy</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">result</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
                <span class="k">return</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">res</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_tensor</span><span class="p">(</span><span class="n">res</span><span class="p">)</span> <span class="k">else</span> <span class="n">res</span> <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">result</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="fm">__call__</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="n">_call_impl</span>

    <span class="k">def</span> <span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="k">if</span> <span class="s1">&#39;_parameters&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
            <span class="n">_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s1">&#39;_parameters&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">_parameters</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">_parameters</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;_buffers&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
            <span class="n">_buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s1">&#39;_buffers&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">_buffers</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">_buffers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;_modules&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
            <span class="n">modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s1">&#39;_modules&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">modules</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;&#39;</span><span class="si">{}</span><span class="s2">&#39; object has no attribute &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">remove_from</span><span class="p">(</span><span class="o">*</span><span class="n">dicts_or_sets</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dicts_or_sets</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">d</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                        <span class="k">del</span> <span class="n">d</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">d</span><span class="o">.</span><span class="n">discard</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;_parameters&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                    <span class="s2">&quot;cannot assign parameters before Module.__init__() call&quot;</span><span class="p">)</span>
            <span class="n">remove_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_persistent_buffers_set</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;cannot assign &#39;</span><span class="si">{}</span><span class="s2">&#39; as parameter &#39;</span><span class="si">{}</span><span class="s2">&#39; &quot;</span>
                                <span class="s2">&quot;(torch.nn.Parameter or None expected)&quot;</span>
                                <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">(</span><span class="n">value</span><span class="p">),</span> <span class="n">name</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">modules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;_modules&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Layer</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">modules</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                        <span class="s2">&quot;cannot assign module before Module.__init__() call&quot;</span><span class="p">)</span>
                <span class="n">remove_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_persistent_buffers_set</span><span class="p">)</span>
                <span class="n">modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="n">value</span><span class="o">.</span><span class="n">is_root</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">for</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">Layer</span><span class="p">)</span> <span class="ow">and</span> <span class="n">mod</span><span class="o">.</span><span class="n">uuid</span> <span class="o">!=</span> <span class="n">value</span><span class="o">.</span><span class="n">uuid</span><span class="p">:</span>
                        <span class="n">mod</span><span class="o">.</span><span class="n">is_root</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">reset_name</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uid_prefixs</span><span class="p">)</span>
                <span class="n">value</span><span class="o">.</span><span class="n">relative_name</span> <span class="o">=</span> <span class="n">name</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s1">&#39;relative_name&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">value</span><span class="o">.</span><span class="n">relative_name</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span> <span class="k">else</span> <span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span> <span class="o">+</span> <span class="n">value</span><span class="o">.</span><span class="n">relative_name</span>
            <span class="k">elif</span> <span class="n">modules</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">modules</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;cannot assign &#39;</span><span class="si">{}</span><span class="s2">&#39; as child module &#39;</span><span class="si">{}</span><span class="s2">&#39; &quot;</span>
                                    <span class="s2">&quot;(torch.nn.Module or None expected)&quot;</span>
                                    <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">(</span><span class="n">value</span><span class="p">),</span> <span class="n">name</span><span class="p">))</span>
                <span class="n">modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="n">value</span><span class="o">.</span><span class="n">is_root</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">for</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">Layer</span><span class="p">)</span> <span class="ow">and</span> <span class="n">mod</span><span class="o">.</span><span class="n">uuid</span> <span class="o">!=</span> <span class="n">value</span><span class="o">.</span><span class="n">uuid</span><span class="p">:</span>
                        <span class="n">mod</span><span class="o">.</span><span class="n">is_root</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">reset_name</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uid_prefixs</span><span class="p">)</span>
                <span class="n">value</span><span class="o">.</span><span class="n">relative_name</span> <span class="o">=</span> <span class="n">name</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s1">&#39;relative_name&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">value</span><span class="o">.</span><span class="n">relative_name</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span> <span class="k">else</span> <span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span> <span class="o">+</span> <span class="n">value</span><span class="o">.</span><span class="n">relative_name</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;_buffers&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">buffers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">buffers</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;cannot assign &#39;</span><span class="si">{}</span><span class="s2">&#39; as buffer &#39;</span><span class="si">{}</span><span class="s2">&#39; &quot;</span>
                                        <span class="s2">&quot;(torch.Tensor or None expected)&quot;</span>
                                        <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">(</span><span class="n">value</span><span class="p">),</span> <span class="n">name</span><span class="p">))</span>
                    <span class="n">buffers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">object</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Override to support `copy.deepcopy` and pickling.</span>
        <span class="c1"># Thread-local objects cannot be copied in Python 3, so pop these.</span>
        <span class="c1"># so shouldn&#39;t be copied.</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1"># state.pop(&#39;_thread_local&#39;, None)</span>
        <span class="c1"># state.pop(&#39;_metrics_lock&#39;, None)</span>
        <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># state[&#39;_thread_local&#39;] = threading.local()</span>
        <span class="c1"># state[&#39;_metrics_lock&#39;] = threading.Lock()</span>
        <span class="c1"># Bypass Trackable logic as `__dict__` already contains this info.</span>
        <span class="nb">object</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;__dict__&#39;</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># We treat the extra repr like the submodule, one item per line</span>
        <span class="n">extra_lines</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">extra_repr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_repr</span><span class="p">()</span>
        <span class="c1"># empty string will be split into list [&#39;&#39;]</span>
        <span class="k">if</span> <span class="n">extra_repr</span><span class="p">:</span>
            <span class="n">extra_lines</span> <span class="o">=</span> <span class="n">extra_repr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">child_lines</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">mod_str</span> <span class="o">=</span> <span class="nb">repr</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
            <span class="n">mod_str</span> <span class="o">=</span> <span class="n">addindent</span><span class="p">(</span><span class="n">mod_str</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">child_lines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;(&#39;</span> <span class="o">+</span> <span class="n">key</span> <span class="o">+</span> <span class="s1">&#39;): &#39;</span> <span class="o">+</span> <span class="n">mod_str</span><span class="p">)</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="n">extra_lines</span> <span class="o">+</span> <span class="n">child_lines</span>

        <span class="n">main_str</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_name</span><span class="p">()</span> <span class="o">+</span> <span class="s1">&#39;(&#39;</span>
        <span class="k">if</span> <span class="n">lines</span><span class="p">:</span>
            <span class="c1"># simple one-liner info, which most builtin Modules will use</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">extra_lines</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">child_lines</span><span class="p">:</span>
                <span class="n">main_str</span> <span class="o">+=</span> <span class="n">extra_lines</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">main_str</span> <span class="o">+=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">  &#39;</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">  &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>

        <span class="n">main_str</span> <span class="o">+=</span> <span class="s1">&#39;)&#39;</span>
        <span class="k">return</span> <span class="n">main_str</span></div>




<div class="viewcode-block" id="Sequential"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Sequential">[docs]</a><span class="k">class</span> <span class="nc">Sequential</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;A sequential container.</span>
<span class="sd">    Modules will be added to it in the order they are passed in the constructor.</span>
<span class="sd">    Alternatively, an ordered dict of modules can also be passed in.</span>

<span class="sd">    To make it easier to understand, here is a small example::</span>

<span class="sd">        # Example of using Sequential</span>
<span class="sd">        model = nn.Sequential(</span>
<span class="sd">                  nn.Conv2d(1,20,5),</span>
<span class="sd">                  nn.ReLU(),</span>
<span class="sd">                  nn.Conv2d(20,64,5),</span>
<span class="sd">                  nn.ReLU()</span>
<span class="sd">                )</span>

<span class="sd">        # Example of using Sequential with OrderedDict</span>
<span class="sd">        model = nn.Sequential(OrderedDict([</span>
<span class="sd">                  (&#39;conv1&#39;, nn.Conv2d(1,20,5)),</span>
<span class="sd">                  (&#39;relu1&#39;, nn.ReLU()),</span>
<span class="sd">                  (&#39;conv2&#39;, nn.Conv2d(20,64,5)),</span>
<span class="sd">                  (&#39;relu2&#39;, nn.ReLU())</span>
<span class="sd">                ]))</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Sequential</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_built</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">uuid</span> <span class="o">=</span> <span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">()</span><span class="o">.</span><span class="n">node</span>
        <span class="n">args</span> <span class="o">=</span> <span class="n">unpack_singleton</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="p">(</span><span class="nb">dict</span><span class="p">,</span> <span class="n">OrderedDict</span><span class="p">,</span> <span class="n">ModuleDict</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">module</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">key</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">,</span> <span class="n">ModuleList</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">module</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">module</span><span class="o">.</span><span class="n">_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">_name</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">module</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<div class="viewcode-block" id="Sequential.build"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Sequential.build">[docs]</a>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">:</span> <span class="n">TensorShape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            input_shape (torch.Size, tensor, list(int), tuple(int)): The input_shape information, not including batch axis.</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_built</span> <span class="o">==</span> <span class="kc">False</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_shape</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_built</span> <span class="o">=</span> <span class="kc">True</span></div>

<div class="viewcode-block" id="Sequential.add_module"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Sequential.add_module">[docs]</a>    <span class="k">def</span> <span class="nf">add_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds a child module to the current module.</span>

<span class="sd">        The module can be accessed as an attribute using the given name.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (string): name of the child module. The child module can be</span>
<span class="sd">                accessed from this module using the given name</span>
<span class="sd">            module (Module): child module to be added to the module.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">built</span> <span class="ow">and</span> <span class="bp">self</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_output_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">last_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_output_shape</span>
            <span class="n">dummay_input</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">last_output</span><span class="o">.</span><span class="n">get_dummy_tensor</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">dummay_input</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">module</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">OrderedDict</span><span class="p">):</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">tensor_to_shape</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">need_exclude_batch_axis</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">is_singleton</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">out</span><span class="o">.</span><span class="n">value_list</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">get_root</span><span class="p">()</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">out</span><span class="o">.</span><span class="n">item_list</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">get_root</span><span class="p">()</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor_to_shape</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">need_exclude_batch_axis</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">is_singleton</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">enforce_singleton</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="n">tensor_to_shape</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">need_exclude_batch_axis</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">is_singleton</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">key_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span>
                <span class="c1"># if len(self.get_root().signature.outputs) &gt; 0:</span>
                <span class="c1">#     self.get_root().signature=get_signature(self)</span>
                <span class="c1"># else:</span>
                <span class="c1">#     self.get_root().signature.outputs[&#39;output&#39;] = self._output_shape.copy()</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span><span class="s1">&#39;_signature&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">module</span><span class="o">.</span><span class="n">_signature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">module</span><span class="o">.</span><span class="n">_signature</span><span class="o">=</span><span class="n">get_signature</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
            <span class="n">sig</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">_signature</span><span class="p">)</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">Sequential</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="o">=</span> <span class="n">sig</span>
            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">outputs</span><span class="p">)</span></div>


<div class="viewcode-block" id="Sequential.remove_at"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Sequential.remove_at">[docs]</a>    <span class="k">def</span> <span class="nf">remove_at</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="fm">__delitem__</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_output_shape</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="p">,</span> <span class="n">Signature</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">key_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_output_shape</span></div>

    <span class="k">def</span> <span class="nf">_get_item_by_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the idx-th item of the iterator&quot;&quot;&quot;</span>
        <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">idx</span><span class="o">.</span><span class="fm">__index__</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="o">-</span><span class="n">size</span> <span class="o">&lt;=</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="n">size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="s1">&#39;index </span><span class="si">{}</span><span class="s1"> is out of range&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
        <span class="n">idx</span> <span class="o">%=</span> <span class="n">size</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="n">islice</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>

    <span class="nd">@_copy_to_script_wrapper</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="n">returnDict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">())[</span><span class="n">idx</span><span class="p">]:</span>
                <span class="n">returnDict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">returnDict</span><span class="o">.</span><span class="n">value_list</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_item_by_idx</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">idx</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_item_by_idx</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">idx</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__delitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="n">idx</span><span class="p">]:</span>
                <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_item_by_idx</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">idx</span><span class="p">)</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>

    <span class="nd">@_copy_to_script_wrapper</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span>

    <span class="nd">@_copy_to_script_wrapper</span>
    <span class="k">def</span> <span class="fm">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">Sequential</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">()</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">key</span><span class="o">.</span><span class="n">isdigit</span><span class="p">()]</span>
        <span class="k">return</span> <span class="n">keys</span>

    <span class="nd">@_copy_to_script_wrapper</span>
    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]:</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

<div class="viewcode-block" id="Sequential.forward"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Sequential.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">unpack_singleton</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="c1"># x = enforce_singleton(x)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>  <span class="c1"># self,x</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">enforce_singleton</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="c1">#class_name=module.__class__.__name__.lower()</span>
            <span class="c1"># if &#39;lstm&#39; in class_name or &#39;gru&#39; in class_name:</span>
            <span class="c1">#     if isinstance(x,tuple):</span>
            <span class="c1">#         x,hx=x</span>
            <span class="c1">#         kwargs[&#39;hx&#39;]=hx</span>

        <span class="k">return</span> <span class="n">x</span></div></div>


<div class="viewcode-block" id="ModuleList"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.ModuleList">[docs]</a><span class="k">class</span> <span class="nc">ModuleList</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Holds submodules in a list.</span>

<span class="sd">    :class:`~torch.nn.ModuleList` can be indexed like a regular Python list, but</span>
<span class="sd">    modules it contains are properly registered, and will be visible by all</span>
<span class="sd">    :class:`~torch.nn.Module` methods.</span>

<span class="sd">    Args:</span>
<span class="sd">        modules (iterable, optional): an iterable of modules to add</span>

<span class="sd">    Examples:</span>

<span class="sd">        class MyModule(nn.Module):</span>
<span class="sd">            def __init__(self):</span>
<span class="sd">                super(MyModule, self).__init__()</span>
<span class="sd">                self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])</span>

<span class="sd">            def forward(self, x, **kwargs):</span>
<span class="sd">                # ModuleList can act as an iterable, or be indexed using ints</span>
<span class="sd">                for i, l in enumerate(self.linears):</span>
<span class="sd">                    x = self.linears[i // 2](x) + l(x)</span>
<span class="sd">                return x</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">modules</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keep_output</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ModuleList</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">keep_output</span><span class="o">=</span><span class="n">keep_output</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">uuid</span> <span class="o">=</span> <span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">()</span><span class="o">.</span><span class="n">node</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">modules</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">modules</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">modules</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_abs_string_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the absolute index for the list of modules&quot;&quot;&quot;</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="s1">&#39;index </span><span class="si">{}</span><span class="s1"> is out of range&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

    <span class="nd">@_copy_to_script_wrapper</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">idx</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_abs_string_index</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span>
            <span class="n">layer</span><span class="o">.</span><span class="n">_nodes</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">layer</span>

    <span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_abs_string_index</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">module</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__delitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">))[</span><span class="n">idx</span><span class="p">]:</span>
                <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_abs_string_index</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
        <span class="c1"># To preserve numbering, self._modules is being reconstructed with modules after deletion</span>
        <span class="n">str_indices</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">str_indices</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">())))</span>

    <span class="nd">@_copy_to_script_wrapper</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span>

    <span class="nd">@_copy_to_script_wrapper</span>
    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

    <span class="k">def</span> <span class="fm">__iadd__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">modules</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">modules</span><span class="p">)</span>

    <span class="nd">@_copy_to_script_wrapper</span>
    <span class="k">def</span> <span class="fm">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">ModuleList</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">()</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">key</span><span class="o">.</span><span class="n">isdigit</span><span class="p">()]</span>
        <span class="k">return</span> <span class="n">keys</span>

<div class="viewcode-block" id="ModuleList.insert"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.ModuleList.insert">[docs]</a>    <span class="k">def</span> <span class="nf">insert</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Insert a given module before a given index in the list.</span>

<span class="sd">        Args:</span>
<span class="sd">            index (int): index to insert.</span>
<span class="sd">            module (nn.Module): module to insert</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">),</span> <span class="n">index</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">index</span><span class="p">)]</span> <span class="o">=</span> <span class="n">module</span></div>

<div class="viewcode-block" id="ModuleList.append"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.ModuleList.append">[docs]</a>    <span class="k">def</span> <span class="nf">append</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Appends a given module to the end of the list.</span>

<span class="sd">        Args:</span>
<span class="sd">            module (nn.Module): module to append</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span> <span class="n">module</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="ModuleList.extend"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.ModuleList.extend">[docs]</a>    <span class="k">def</span> <span class="nf">extend</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">modules</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Appends modules from a Python iterable to the end of the list.</span>

<span class="sd">        Args:</span>
<span class="sd">            modules (iterable): iterable of modules to append</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">modules</span><span class="p">,</span> <span class="n">abc</span><span class="o">.</span><span class="n">Iterable</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;ModuleList.extend should be called with an &quot;</span>
                            <span class="s2">&quot;iterable, but got &quot;</span> <span class="o">+</span> <span class="nb">type</span><span class="p">(</span><span class="n">modules</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">modules</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">offset</span> <span class="o">+</span> <span class="n">i</span><span class="p">),</span> <span class="n">module</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div></div>




<div class="viewcode-block" id="ModuleDict"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.ModuleDict">[docs]</a><span class="k">class</span> <span class="nc">ModuleDict</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Holds submodules in a dictionary.</span>

<span class="sd">    :class:`~torch.nn.ModuleDict` can be indexed like a regular Python dictionary,</span>
<span class="sd">    but modules it contains are properly registered, and will be visible by all</span>
<span class="sd">    :class:`~torch.nn.Module` methods.</span>

<span class="sd">    :class:`~torch.nn.ModuleDict` is an **ordered** dictionary that respects</span>

<span class="sd">    * the order of insertion, and</span>

<span class="sd">    * in :meth:`~torch.nn.ModuleDict.update`, the order of the merged ``OrderedDict``</span>
<span class="sd">      or another :class:`~torch.nn.ModuleDict` (the argument to :meth:`~torch.nn.ModuleDict.update`).</span>

<span class="sd">    Note that :meth:`~torch.nn.ModuleDict.update` with other unordered mapping</span>
<span class="sd">    types (e.g., Python&#39;s plain ``dict``) does not preserve the order of the</span>
<span class="sd">    merged mapping.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        modules (iterable, optional): a mapping (dictionary) of (string: module)</span>
<span class="sd">            or an iterable of key-value pairs of type (string, module)</span>

<span class="sd">    Example::</span>

<span class="sd">        class MyModule(nn.Module):</span>
<span class="sd">            def __init__(self):</span>
<span class="sd">                super(MyModule, self).__init__()</span>
<span class="sd">                self.choices = nn.ModuleDict({</span>
<span class="sd">                        &#39;conv&#39;: nn.Conv2d(10, 10, 3),</span>
<span class="sd">                        &#39;pool&#39;: nn.MaxPool2d(3)</span>
<span class="sd">                })</span>
<span class="sd">                self.activations = nn.ModuleDict([</span>
<span class="sd">                        [&#39;lrelu&#39;, nn.LeakyReLU()],</span>
<span class="sd">                        [&#39;prelu&#39;, nn.PReLU()]</span>
<span class="sd">                ])</span>

<span class="sd">            def forward(self, x, choice, act):</span>
<span class="sd">                x = self.choices[choice](x)</span>
<span class="sd">                x = self.activations[act](x)</span>
<span class="sd">                return x</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">modules</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Layer</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keep_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">is_multicasting</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ModuleDict</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">keep_output</span><span class="o">=</span><span class="n">keep_output</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">uuid</span> <span class="o">=</span> <span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">()</span><span class="o">.</span><span class="n">node</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_multicasting</span> <span class="o">=</span> <span class="n">is_multicasting</span>
        <span class="k">if</span> <span class="n">modules</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">modules</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">modules</span><span class="p">)</span>

    <span class="c1"># @_copy_to_script_wrapper</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Layer</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">Layer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__delitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

    <span class="nd">@_copy_to_script_wrapper</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span>

    <span class="nd">@_copy_to_script_wrapper</span>
    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span>

    <span class="nd">@_copy_to_script_wrapper</span>
    <span class="k">def</span> <span class="fm">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span>

<div class="viewcode-block" id="ModuleDict.clear"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.ModuleDict.clear">[docs]</a>    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Remove all items from the ModuleDict.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span></div>

<div class="viewcode-block" id="ModuleDict.pop"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.ModuleDict.pop">[docs]</a>    <span class="k">def</span> <span class="nf">pop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Layer</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Remove key from the ModuleDict and return its module.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            key (string): key to pop from the ModuleDict</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">del</span> <span class="bp">self</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">v</span></div>

    <span class="c1"># @_copy_to_script_wrapper</span>
<div class="viewcode-block" id="ModuleDict.keys"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.ModuleDict.keys">[docs]</a>    <span class="k">def</span> <span class="nf">keys</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return an iterable of the ModuleDict keys.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span></div>

    <span class="c1"># @_copy_to_script_wrapper</span>
<div class="viewcode-block" id="ModuleDict.items"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.ModuleDict.items">[docs]</a>    <span class="k">def</span> <span class="nf">items</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Layer</span><span class="p">]]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return an iterable of the ModuleDict key/value pairs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">()</span></div>

    <span class="c1"># @_copy_to_script_wrapper</span>
<div class="viewcode-block" id="ModuleDict.values"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.ModuleDict.values">[docs]</a>    <span class="k">def</span> <span class="nf">values</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">Layer</span><span class="p">]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return an iterable of the ModuleDict values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">()</span></div>

<div class="viewcode-block" id="ModuleDict.update"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.ModuleDict.update">[docs]</a>    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">modules</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Layer</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Update the :class:`~torch.nn.ModuleDict` with the key-value pairs from a</span>
<span class="sd">        mapping or an iterable, overwriting existing keys.</span>

<span class="sd">        note::</span>
<span class="sd">            If :attr:`modules` is an ``OrderedDict``, a :class:`~torch.nn.ModuleDict`, or</span>
<span class="sd">            an iterable of key-value pairs, the order of new elements in it is preserved.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            modules (iterable): a mapping (dictionary) from string to :class:`~torch.nn.Module`,</span>
<span class="sd">                or an iterable of key-value pairs of type (string, :class:`~torch.nn.Module`)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">modules</span><span class="p">,</span> <span class="n">abc</span><span class="o">.</span><span class="n">Iterable</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;ModuleDict.update should be called with an &quot;</span>
                            <span class="s2">&quot;iterable of key/value pairs, but got &quot;</span> <span class="o">+</span>
                            <span class="nb">type</span><span class="p">(</span><span class="n">modules</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">modules</span><span class="p">,</span> <span class="p">(</span><span class="n">OrderedDict</span><span class="p">,</span> <span class="n">ModuleDict</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">module</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">modules</span><span class="p">,</span> <span class="n">abc</span><span class="o">.</span><span class="n">Mapping</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">modules</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
                <span class="bp">self</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">module</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">modules</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">abc</span><span class="o">.</span><span class="n">Iterable</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;ModuleDict update sequence element &quot;</span>
                                    <span class="s2">&quot;#&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">j</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; should be Iterable; is&quot;</span> <span class="o">+</span>
                                    <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;ModuleDict update sequence element &quot;</span>
                                     <span class="s2">&quot;#&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">j</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; has length &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="p">))</span> <span class="o">+</span>
                                     <span class="s2">&quot;; 2 is required&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="p">[</span><span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">m</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span></div>

<div class="viewcode-block" id="ModuleDict.build"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.ModuleDict.build">[docs]</a>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">:</span> <span class="n">TensorShape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            input_shape (torch.Size, tensor, list(int), tuple(int)): The input_shape information, not including batch axis.</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_built</span> <span class="o">==</span> <span class="kc">False</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_root</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_input_shape</span> <span class="o">=</span> <span class="n">input_shape</span>

                <span class="n">dummay_input</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_shape</span><span class="o">.</span><span class="n">get_dummy_tensor</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">dummay_input</span><span class="p">)</span>
                    <span class="n">module</span><span class="o">.</span><span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_shape</span>
                    <span class="n">module</span><span class="o">.</span><span class="n">output_shape</span> <span class="o">=</span> <span class="n">tensor_to_shape</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_built</span> <span class="o">=</span> <span class="kc">True</span></div>

<div class="viewcode-block" id="ModuleDict.forward"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.ModuleDict.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_multicasting</span><span class="p">:</span>
            <span class="c1"># x = enforce_singleton(x)</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="n">results</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span>
            <span class="k">return</span> <span class="n">results</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="Combine"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Combine">[docs]</a><span class="k">class</span> <span class="nc">Combine</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;A sequential container.</span>
<span class="sd">    Modules will be added to it in the order they are passed in the constructor.</span>
<span class="sd">    Alternatively, an ordered dict of modules can also be passed in.</span>

<span class="sd">    To make it easier to understand, here is a small example::</span>

<span class="sd">        # Example of using Sequential</span>
<span class="sd">        model = nn.Sequential(</span>
<span class="sd">                  nn.Conv2d(1,20,5),</span>
<span class="sd">                  nn.ReLU(),</span>
<span class="sd">                  nn.Conv2d(20,64,5),</span>
<span class="sd">                  nn.ReLU()</span>
<span class="sd">                )</span>

<span class="sd">        # Example of using Sequential with OrderedDict</span>
<span class="sd">        model = nn.Sequential(OrderedDict([</span>
<span class="sd">                  (&#39;conv1&#39;, nn.Conv2d(1,20,5)),</span>
<span class="sd">                  (&#39;relu1&#39;, nn.ReLU()),</span>
<span class="sd">                  (&#39;conv2&#39;, nn.Conv2d(20,64,5)),</span>
<span class="sd">                  (&#39;relu2&#39;, nn.ReLU())</span>
<span class="sd">                ]))</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Combine</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">uuid</span> <span class="o">=</span> <span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">()</span><span class="o">.</span><span class="n">node</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_built</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">OrderedDict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">module</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">module</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_item_by_idx</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the idx-th item of the iterator&quot;&quot;&quot;</span>
        <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">idx</span><span class="o">.</span><span class="fm">__index__</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="o">-</span><span class="n">size</span> <span class="o">&lt;=</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="n">size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="s1">&#39;index </span><span class="si">{}</span><span class="s1"> is out of range&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
        <span class="n">idx</span> <span class="o">%=</span> <span class="n">size</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="n">islice</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="n">OrderedDict</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">())[</span><span class="n">idx</span><span class="p">]))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_item_by_idx</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">idx</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_item_by_idx</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">idx</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__delitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="n">idx</span><span class="p">]:</span>
                <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_item_by_idx</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">idx</span><span class="p">)</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">Combine</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">()</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">key</span><span class="o">.</span><span class="n">isdigit</span><span class="p">()]</span>
        <span class="k">return</span> <span class="n">keys</span>

<div class="viewcode-block" id="Combine.add_module"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Combine.add_module">[docs]</a>    <span class="k">def</span> <span class="nf">add_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adds a child module to the current module.</span>

<span class="sd">        The module can be accessed as an attribute using the given name.</span>
<span class="sd">        1) add module as child</span>

<span class="sd">        2) generate default_name and relative_name</span>

<span class="sd">        3) update the nodes</span>

<span class="sd">        Args:</span>
<span class="sd">            name (string): name of the child module. The child module can be</span>
<span class="sd">                accessed from this module using the given name</span>
<span class="sd">            module (Module): child module to be added to the module.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">Layer</span><span class="p">))</span> <span class="ow">and</span> <span class="n">module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> is not a Module subclass&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">(</span><span class="n">module</span><span class="p">)))</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_six</span><span class="o">.</span><span class="n">string_classes</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;module name should be a string. Got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">(</span><span class="n">name</span><span class="p">)))</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;attribute &#39;</span><span class="si">{}</span><span class="s2">&#39; already exists&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
        <span class="k">elif</span> <span class="s1">&#39;.&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
            <span class="c1"># name=name.replace(&#39;.&#39;,&#39;_&#39;)</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;module name can&#39;t contain </span><span class="se">\&quot;</span><span class="s2">.</span><span class="se">\&quot;</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;module name can&#39;t be empty string </span><span class="se">\&quot;\&quot;</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">module</span></div>

<div class="viewcode-block" id="Combine.build"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Combine.build">[docs]</a>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">input_shape</span><span class="p">:</span> <span class="n">TensorShape</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_built</span><span class="p">:</span>
            <span class="c1"># Signature(name=self.name)</span>
            <span class="k">for</span> <span class="n">shp</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
                <span class="c1"># shp = tensor_to_shape(inp, need_exclude_batch_axis=True, is_singleton=False)</span>
                <span class="n">module</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">shp</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_built</span> <span class="o">=</span> <span class="kc">True</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">signature</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="o">=</span> <span class="n">Signature</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">inp_k</span><span class="p">,</span> <span class="n">inp_v</span> <span class="ow">in</span> <span class="n">v</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="s1">&#39;</span><span class="si">{0}</span><span class="s1">_</span><span class="si">{1}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">inp_k</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;</span><span class="si">{0}</span><span class="s1">_</span><span class="si">{1}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">inp_k</span><span class="p">,</span> <span class="n">k</span><span class="p">)]</span> <span class="o">=</span> <span class="n">inp_v</span>
            <span class="k">for</span> <span class="n">out_k</span><span class="p">,</span> <span class="n">out_v</span> <span class="ow">in</span> <span class="n">v</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="s1">&#39;</span><span class="si">{0}</span><span class="s1">_</span><span class="si">{1}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">out_k</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;</span><span class="si">{0}</span><span class="s1">_</span><span class="si">{1}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">out_k</span><span class="p">,</span> <span class="n">k</span><span class="p">)]</span> <span class="o">=</span> <span class="n">out_v</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span>

    <span class="nd">@signature</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">signature</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_signature</span> <span class="o">=</span> <span class="n">value</span>

<div class="viewcode-block" id="Combine.combine_forward"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Combine.combine_forward">[docs]</a>    <span class="k">def</span> <span class="nf">combine_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">inp</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">())):</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">module</span><span class="p">(</span><span class="n">inp</span><span class="p">))</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span></div>

<div class="viewcode-block" id="Combine.forward"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.Combine.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">inp</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">())):</span>
                <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">module</span><span class="p">(</span><span class="n">inp</span><span class="p">))</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">module</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span></div></div>




<div class="viewcode-block" id="print_network"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.print_network">[docs]</a><span class="k">def</span> <span class="nf">print_network</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">num_params</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
        <span class="n">num_params</span> <span class="o">+=</span> <span class="n">param</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Total number of parameters: </span><span class="si">%d</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">num_params</span><span class="p">)</span></div>


<div class="viewcode-block" id="summary"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.summary">[docs]</a><span class="k">def</span> <span class="nf">summary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_specs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">register_hook</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
            <span class="c1"># class_name =module.re    module.name   # str(module.__class__).split(&quot;.&quot;)[-1].split(&quot;&#39;&quot;)[0]</span>
            <span class="n">module_idx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>

            <span class="n">m_key</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">relative_name</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;relative_name&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">module</span><span class="o">.</span><span class="n">name</span>
            <span class="k">if</span> <span class="n">m_key</span> <span class="ow">in</span> <span class="n">summary</span><span class="p">:</span>
                <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;visits&quot;</span><span class="p">]</span><span class="o">+=</span><span class="mi">1</span>
                <span class="n">visit</span><span class="o">=</span><span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;visits&quot;</span><span class="p">]</span>
                <span class="n">m_key</span><span class="o">=</span><span class="n">m_key</span><span class="o">+</span><span class="s1">&#39;_</span><span class="si">{0}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">visit</span><span class="p">)</span>

            <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
            <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;visits&quot;</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span>
            <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;class_name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;keep_output&#39;</span><span class="p">):</span>
                <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;keep_output&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">keep_output</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;keep_output&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">iteration_tools</span><span class="o">.</span><span class="n">flatten</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">iterable_types</span><span class="o">=</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">unpack_singleton</span><span class="p">([</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">input</span> <span class="k">if</span> <span class="n">item</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
                <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;input_shape&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">int_shape</span><span class="p">(</span><span class="nb">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
                <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;input_shape&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">int_shape</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]))</span>
            <span class="k">elif</span> <span class="n">is_tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
                <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;input_shape&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">int_shape</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
            <span class="k">if</span> <span class="s2">&quot;input_shape&quot;</span> <span class="ow">in</span> <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">]</span>  <span class="ow">and</span>  <span class="nb">len</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;input_shape&quot;</span><span class="p">])</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
                <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;input_shape&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_size</span>

            <span class="n">output</span> <span class="o">=</span> <span class="n">iteration_tools</span><span class="o">.</span><span class="n">flatten</span><span class="p">([</span><span class="n">output</span><span class="p">],</span> <span class="n">iterable_types</span><span class="o">=</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">unpack_singleton</span><span class="p">([</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">output</span> <span class="k">if</span> <span class="n">item</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;output_shape&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">int_shape</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
            <span class="k">elif</span> <span class="n">is_instance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span><span class="s1">&#39;OrderedDict&#39;</span><span class="p">):</span>
                <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;output_shape&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">int_shape</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]]))</span>
            <span class="k">elif</span> <span class="n">is_tensor</span><span class="p">(</span><span class="n">output</span><span class="p">):</span>
                <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;output_shape&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">int_shape</span><span class="p">(</span><span class="n">output</span><span class="p">))</span>
            <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;output_shape&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_size</span>

            <span class="n">params</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;flops&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;macc&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;trainable&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
            <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;bias&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">para</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">para</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">para_type</span> <span class="o">=</span> <span class="s2">&quot;weight&quot;</span>
                    <span class="k">if</span> <span class="s1">&#39;bias&#39;</span> <span class="ow">in</span> <span class="n">name</span> <span class="ow">or</span> <span class="s1">&#39;beta&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                        <span class="n">para_type</span> <span class="o">=</span> <span class="s2">&quot;bias&quot;</span>

                    <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="n">para_type</span><span class="p">][</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">int_shape</span><span class="p">(</span><span class="n">para</span><span class="p">))</span>
                    <span class="n">num_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">int_shape</span><span class="p">(</span><span class="n">para</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
                    <span class="n">spatial_dims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;output_shape&quot;</span><span class="p">][</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
                    <span class="n">params</span> <span class="o">+=</span> <span class="n">num_params</span>
                    <span class="k">if</span> <span class="n">para</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                        <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;trainable&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">num_params</span>

                    <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;flops&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">num_params</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">spatial_dims</span>
                    <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;macc&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">num_params</span> <span class="o">*</span> <span class="n">spatial_dims</span>

            <span class="n">summary</span><span class="p">[</span><span class="n">m_key</span><span class="p">][</span><span class="s2">&quot;nb_params&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">params</span>

        <span class="k">if</span> <span class="p">(</span>
                <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">,</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">,</span> <span class="n">ModuleList</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">,</span> <span class="n">ModuleDict</span><span class="p">))</span>
                <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span><span class="n">module</span> <span class="o">==</span> <span class="n">model</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">_parameters</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">hooks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">register_forward_hook</span><span class="p">(</span><span class="n">hook</span><span class="p">))</span>

    <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span><span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">device</span><span class="o">.</span><span class="vm">__name__</span>
    <span class="k">assert</span> <span class="n">device</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
        <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="s2">&quot;tpu&quot;</span><span class="p">,</span>
        <span class="s2">&quot;xla&quot;</span><span class="p">,</span>
    <span class="p">],</span> <span class="s2">&quot;Input device is not valid, please specify &#39;cuda&#39; or &#39;cpu&#39;&quot;</span>

    <span class="c1"># if device == &quot;cuda&quot; and torch.cuda.is_available():</span>
    <span class="c1">#     dtype = torch.cuda.FloatTensor</span>
    <span class="c1"># else:</span>
    <span class="c1">#     dtype = torch.FloatTensor</span>

    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="n">module</span><span class="o">.</span><span class="n">relative_name</span> <span class="o">=</span> <span class="n">name</span>
    <span class="c1"># multiple inputs to the network</span>

    <span class="c1"># prevent pytorch &#39;ValueError: Expected more than 1 value per channel when training, got input size ....</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">get_device</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="c1"># batch_size of 2 for batchnorm</span>
    <span class="c1"># if module.signature is not None:</span>
    <span class="c1">#     input_tensor = [to_tensor(module.signature.inputs.value_list[k].get_dummy_tensor()) for k in  range(module.signature.inputs.value_list) if not module.signature.inputs.value_list[k].optional or k==0]</span>
    <span class="c1">#</span>
    <span class="n">inps</span><span class="o">=</span><span class="n">OrderedDict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">input_specs</span><span class="p">:</span>
        <span class="n">k</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">name</span>
        <span class="k">if</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">_dims</span><span class="o">!=</span><span class="p">[</span><span class="kc">None</span><span class="p">]:</span>
            <span class="n">inps</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">get_dummy_tensor</span><span class="p">(),</span><span class="n">device</span><span class="o">=</span><span class="n">get_device</span><span class="p">())</span>
        <span class="k">elif</span> <span class="n">v</span><span class="o">.</span><span class="n">optional</span><span class="p">:</span>
            <span class="n">inps</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">default</span>
        <span class="k">elif</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">inps</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inps</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>


    <span class="c1">#x = [to_tensor(inps[n].get_dummy_tensor(),device=get_device())  for n in range(len(inps)) if inps[n].optional == False or  inps[n].shape._dims!=[None]]</span>
    <span class="c1"># p    rint(type(x[0]))</span>

    <span class="c1"># create properties</span>
    <span class="n">summary</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
    <span class="n">hooks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># register hook</span>
        <span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">register_hook</span><span class="p">)</span>

        <span class="c1"># make a forward pass</span>
        <span class="c1"># print(x.shape)</span>
        <span class="k">if</span> <span class="n">inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">OrderedDict</span><span class="p">):</span>
                <span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">inps</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
                <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">inps</span><span class="o">.</span><span class="n">value_list</span><span class="p">)</span>

        <span class="c1"># remove these hooks</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">hooks</span><span class="p">:</span>
            <span class="n">h</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>
        <span class="n">max_name_len</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">max_weight_len</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">summary</span><span class="p">:</span>
            <span class="n">max_name_len</span> <span class="o">=</span> <span class="n">builtins</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">max_name_len</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span> <span class="o">+</span> <span class="s2">&quot;  [&quot;</span> <span class="o">+</span> <span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;class_name&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;]&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">5</span><span class="p">)</span>
            <span class="n">max_weight_len</span> <span class="o">=</span> <span class="n">builtins</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">max_weight_len</span><span class="p">,</span> <span class="n">builtins</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;(&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;)&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">))</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span> <span class="o">+</span> <span class="mi">5</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span>
                <span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;weight&quot;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">5</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--------------------------------------------------------------------------------------------------------------------------------&quot;</span><span class="p">)</span>
        <span class="n">line_new</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{0:^50s}</span><span class="s2"> </span><span class="si">{1:&lt;25s}</span><span class="s2">  </span><span class="si">{2:&lt;35s}</span><span class="s2"> </span><span class="si">{3:&lt;8s}</span><span class="s2">  </span><span class="si">{4:&lt;8s}</span><span class="s2">  </span><span class="si">{5:&lt;25s}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;50s&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">max_name_len</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;s&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;35s&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">max_weight_len</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;s&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;Layer (type)&quot;</span><span class="p">,</span>
                                                                                                                                                                     <span class="s2">&quot;Output Shape&quot;</span><span class="p">,</span>
                                                                                                                                                                     <span class="s2">&quot;Weight &quot;</span><span class="p">,</span> <span class="s2">&quot;Bias&quot;</span><span class="p">,</span>
                                                                                                                                                                     <span class="s2">&quot;Param #&quot;</span><span class="p">,</span>
                                                                                                                                                                     <span class="s2">&quot;FLOPS #&quot;</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="n">line_new</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==============================================================================&quot;</span><span class="p">)</span>
        <span class="n">total_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">total_output</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">trainable_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">flops</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">macc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">summary</span><span class="p">:</span>
            <span class="c1"># input_shape, output_shape, trainable, nb_params</span>
            <span class="n">is_keep</span> <span class="o">=</span> <span class="s1">&#39;★&#39;</span> <span class="k">if</span> <span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;keep_output&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
            <span class="n">class_name</span> <span class="o">=</span> <span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;class_name&quot;</span><span class="p">]</span>
            <span class="c1"># line_new = &quot;{0:&lt;50s} {1:&lt;20s}  {2:&lt;20s} {3:&lt;8s}  {4:&lt;8}  {5:&lt;12}&quot;.format(</span>
            <span class="c1">#     layer+&quot;  &quot;+class_name,</span>
            <span class="c1">#     is_keep + str(summary[layer][&quot;output_shape&quot;]),</span>
            <span class="c1">#     str(summary[layer][&quot;weight&quot;] if &#39;weight&#39; in summary[layer] else &#39;&#39;),</span>
            <span class="c1">#     str(summary[layer][&quot;bias&quot;] if &#39;bias&#39; in summary[layer] else &#39;&#39;),</span>
            <span class="c1">#     summary[layer][&quot;nb_params&quot;],</span>
            <span class="c1">#     summary[layer][&quot;flops&quot;][0]</span>
            <span class="c1"># )</span>

            <span class="n">line_new</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{0:&lt;50s}</span><span class="s2"> </span><span class="si">{1:&lt;25s}</span><span class="s2">  </span><span class="si">{2:&lt;35s}</span><span class="s2"> </span><span class="si">{3:&lt;8s}</span><span class="s2">  </span><span class="si">{4:,.0f}</span><span class="s2">  </span><span class="si">{5:,.0f}</span><span class="s2">  &quot;</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;50s&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">max_name_len</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;s&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;35s&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">max_weight_len</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;s&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="p">(</span><span class="n">layer</span> <span class="o">+</span> <span class="s2">&quot;  [&quot;</span> <span class="o">+</span> <span class="n">class_name</span> <span class="o">+</span> <span class="s2">&quot;]&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">max_name_len</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">),</span>
                <span class="p">(</span><span class="n">is_keep</span> <span class="o">+</span> <span class="nb">str</span><span class="p">([</span><span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;output_shape&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">:]))</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">),</span>
                <span class="nb">str</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">item_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="s1">&#39;weight&#39;</span> <span class="ow">in</span> <span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;weight&quot;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39; &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;(&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;)&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span>
                    <span class="n">max_weight_len</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">),</span>
                <span class="nb">str</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;bias&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">item_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="s1">&#39;bias&#39;</span> <span class="ow">in</span> <span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;bias&quot;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39; &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;(&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;)&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">),</span>
                <span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;nb_params&quot;</span><span class="p">],</span>
                <span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;flops&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;weight&quot;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;weight&quot;</span><span class="p">])):</span>
                    <span class="n">line_new_add</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{0:&lt;50s}</span><span class="s2"> </span><span class="si">{1:&lt;25s}</span><span class="s2">  </span><span class="si">{2:&lt;35s}</span><span class="s2"> </span><span class="si">{3:&lt;8s}</span><span class="s2">  </span><span class="si">{4}</span><span class="s2">  </span><span class="si">{5}</span><span class="s2">  &quot;</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;50s&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">max_name_len</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;s&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;35s&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">max_weight_len</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;s&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">max_name_len</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span> <span class="o">+</span> <span class="s2">&quot;  [&quot;</span> <span class="o">+</span> <span class="n">class_name</span> <span class="o">+</span> <span class="s2">&quot;]&quot;</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">),</span>
                        <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="mi">25</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">is_keep</span> <span class="o">+</span> <span class="nb">str</span><span class="p">([</span><span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;output_shape&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">:]))</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">),</span>
                        <span class="nb">str</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">item_list</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;weight&quot;</span><span class="p">])</span> <span class="k">else</span> <span class="s1">&#39; &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;(&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;)&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">max_weight_len</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">),</span>
                        <span class="nb">str</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;bias&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">item_list</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;bias&quot;</span><span class="p">])</span> <span class="k">else</span> <span class="s1">&#39; &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;(&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;)&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">),</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
                    <span class="n">line_new</span> <span class="o">=</span> <span class="n">line_new</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">line_new_add</span>

            <span class="n">total_params</span> <span class="o">+=</span> <span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;nb_params&quot;</span><span class="p">]</span>
            <span class="n">flops</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;flops&quot;</span><span class="p">])</span>
            <span class="n">macc</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;macc&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
            <span class="n">total_output</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;output_shape&quot;</span><span class="p">])</span>
            <span class="k">if</span> <span class="s2">&quot;trainable&quot;</span> <span class="ow">in</span> <span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">]:</span>
                <span class="n">trainable_params</span> <span class="o">+=</span> <span class="n">summary</span><span class="p">[</span><span class="n">layer</span><span class="p">][</span><span class="s2">&quot;trainable&quot;</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">line_new</span><span class="p">)</span>

        <span class="c1"># assume 4 bytes/number (float on cuda).</span>
        <span class="n">total_input_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="mf">4.</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">))</span> <span class="k">for</span> <span class="n">spec</span> <span class="ow">in</span> <span class="n">input_specs</span> <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">optional</span> <span class="o">==</span> <span class="kc">False</span> <span class="ow">and</span> <span class="n">spec</span><span class="o">.</span><span class="n">shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">total_output_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">total_output</span> <span class="o">*</span> <span class="mf">4.</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">))</span>  <span class="c1"># x2 for gradients</span>
        <span class="n">total_params_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">total_params</span> <span class="o">*</span> <span class="mf">4.</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">**</span> <span class="mf">2.</span><span class="p">))</span>
        <span class="n">total_size</span> <span class="o">=</span> <span class="n">total_params_size</span> <span class="o">+</span> <span class="n">total_output_size</span> <span class="o">+</span> <span class="n">total_input_size</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;================================================================&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total params: </span><span class="si">{0:,.0f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">total_params</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Trainable params: </span><span class="si">{0:,.0f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">trainable_params</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Non-trainable params: </span><span class="si">{0:,.0f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">total_params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">trainable_params</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total MACC: </span><span class="si">{0:,.0f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">macc</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total FLOPs: </span><span class="si">{0:.5f}</span><span class="s2"> GFLOPs&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">flops</span> <span class="o">/</span> <span class="mf">10.</span> <span class="o">**</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">)[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------------------------------------------------------------&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Input size (MB): </span><span class="si">%0.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">total_input_size</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Forward/backward pass size (MB): </span><span class="si">%0.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">total_output_size</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Params size (MB): </span><span class="si">%0.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">total_params_size</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Estimated Total Size (MB): </span><span class="si">%0.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">total_size</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------------------------------------------------------------&quot;</span><span class="p">)</span>
        <span class="c1"># return summary</span>
        <span class="k">del</span> <span class="n">hooks</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">hooks</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="n">PrintException</span><span class="p">()</span></div>




<div class="viewcode-block" id="normalize_padding"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.normalize_padding">[docs]</a><span class="k">def</span> <span class="nf">normalize_padding</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">rank</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    normalized format of padding should have length equal to rank+2</span>
<span class="sd">    And the order should follow the order of dimension</span>
<span class="sd">    ex. Conv2d (rank=2) it&#39;s normalized format length:2+2  ==&gt;(left, right,top bottom)</span>

<span class="sd">    Args:</span>
<span class="sd">        padding (None, int, tuple):</span>
<span class="sd">        rank (int):</span>

<span class="sd">    Returns:</span>
<span class="sd">        the normalized format of padding</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; normalize_padding(((1,0),(1,0)),2)</span>
<span class="sd">        (1, 0, 1, 0)</span>
<span class="sd">        &gt;&gt;&gt; normalize_padding((1,0),2)</span>
<span class="sd">        (0, 0, 1, 1)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">padding</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rank</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">padding</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rank</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rank</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span> <span class="o">==</span> <span class="n">rank</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">int</span><span class="p">):</span>
        <span class="c1"># rank=2 (1,1)=&gt;(1,1,1,1)   (1,0)=&gt;(0,0,1,1)</span>
        <span class="n">reversed_padding</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
        <span class="n">reversed_padding</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
        <span class="n">return_padding</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rank</span><span class="p">):</span>
            <span class="n">return_padding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reversed_padding</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">return_padding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reversed_padding</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">return_padding</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span> <span class="o">==</span> <span class="n">rank</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="c1"># rank=2  ((1,0),(1,0)=&gt;(1,0,1,0)</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">padding</span><span class="p">))))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">rank</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
    <span class="k">return</span> <span class="n">padding</span></div>


<div class="viewcode-block" id="print_mem_stack"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.print_mem_stack">[docs]</a><span class="k">def</span> <span class="nf">print_mem_stack</span><span class="p">():</span>  <span class="c1"># pragma: no cover</span>
    <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">gc</span><span class="o">.</span><span class="n">get_objects</span><span class="p">():</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">data</span><span class="p">)):</span>
                <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">),</span> <span class="n">obj</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">pass</span></div>


<span class="k">def</span> <span class="nf">count_mem_items</span><span class="p">():</span>  <span class="c1"># pragma: no cover</span>
    <span class="n">nb_params</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">nb_tensors</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">gc</span><span class="o">.</span><span class="n">get_objects</span><span class="p">():</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">data</span><span class="p">)):</span>
                <span class="n">obj_type</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span>
                <span class="k">if</span> <span class="s1">&#39;parameter&#39;</span> <span class="ow">in</span> <span class="n">obj_type</span><span class="p">:</span>
                    <span class="n">nb_params</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">nb_tensors</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">pass</span>

    <span class="k">return</span> <span class="n">nb_params</span><span class="p">,</span> <span class="n">nb_tensors</span>


<span class="k">def</span> <span class="nf">get_human_readable_count</span><span class="p">(</span><span class="n">number</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abbreviates an integer number with K, M, B, T for thousands, millions,</span>
<span class="sd">    billions and trillions, respectively.</span>
<span class="sd">    Examples:</span>
<span class="sd">        123     -&gt; 123</span>
<span class="sd">        1234    -&gt; 1 K       (one thousand)</span>
<span class="sd">        2e6     -&gt; 2 M       (two million)</span>
<span class="sd">        3e9     -&gt; 3 B       (three billion)</span>
<span class="sd">        4e12    -&gt; 4 T       (four trillion)</span>
<span class="sd">        5e15    -&gt; 5,000 T</span>
<span class="sd">    :param number: a positive integer number</span>
<span class="sd">    :returns a string formatted according to the pattern described above.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">number</span> <span class="o">&gt;=</span> <span class="mi">0</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="s1">&#39;K&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">]</span>
    <span class="n">num_digits</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">number</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">number</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">num_groups</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">num_digits</span> <span class="o">/</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">num_groups</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">num_groups</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>  <span class="c1"># don&#39;t abbreviate beyond trillions</span>
    <span class="n">shift</span> <span class="o">=</span> <span class="o">-</span><span class="mi">3</span> <span class="o">*</span> <span class="p">(</span><span class="n">num_groups</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">number</span> <span class="o">=</span> <span class="n">number</span> <span class="o">*</span> <span class="p">(</span><span class="mi">10</span> <span class="o">**</span> <span class="n">shift</span><span class="p">)</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">num_groups</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="s1">&#39;</span><span class="si">{0:,d}</span><span class="s1"> </span><span class="si">{1}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">number</span><span class="p">),</span><span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>


<div class="viewcode-block" id="try_map_args_and_call"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.try_map_args_and_call">[docs]</a><span class="k">def</span> <span class="nf">try_map_args_and_call</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">OrderedDict</span><span class="p">,</span> <span class="n">data_feed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">is_autocast_enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This function is the core function for mapping callable and argments</span>

<span class="sd">    Args:</span>

<span class="sd">        fn (callable): the callable, maybe functions or layers</span>
<span class="sd">        data (OrderedDict): The key-value pair for available data.</span>
<span class="sd">        data_feed (OrderedDict): The relation between callable argments (key) and data (value)</span>
<span class="sd">        is_autocast_enabled (bool):</span>

<span class="sd">    Returns:</span>
<span class="sd">        The result of the callable base on data_feed</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">fn</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">arg_map</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
            <span class="n">out</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">Layer</span><span class="p">):</span>
                <span class="n">_device</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">get_root</span><span class="p">()</span><span class="o">.</span><span class="n">device</span>
                <span class="n">_signature</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">_signature</span>
                <span class="k">if</span> <span class="kc">None</span> <span class="ow">in</span> <span class="n">fn</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">value_list</span><span class="p">:</span>
                    <span class="n">_signature</span> <span class="o">=</span> <span class="n">get_signature</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">key_list</span><span class="p">:</span>
                    <span class="n">is_optional</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span><span class="o">.</span><span class="n">optional</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fn</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">arg</span><span class="p">],</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span>
                    <span class="n">default</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span><span class="o">.</span><span class="n">default</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fn</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">arg</span><span class="p">],</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
                    <span class="n">is_input</span> <span class="o">=</span> <span class="n">arg</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;input&#39;</span><span class="p">]</span>
                    <span class="n">is_output</span> <span class="o">=</span> <span class="n">arg</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;output&#39;</span><span class="p">,</span> <span class="s1">&#39;y_pred&#39;</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">data_feed</span> <span class="ow">and</span> <span class="n">data_feed</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_feed</span><span class="p">[</span><span class="n">arg</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">_device</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">arg</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">_device</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">is_input</span> <span class="ow">and</span> <span class="s1">&#39;input&#39;</span> <span class="ow">in</span> <span class="n">data_feed</span> <span class="ow">and</span> <span class="n">data_feed</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">]</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_feed</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">_device</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">is_output</span> <span class="ow">and</span> <span class="s1">&#39;output&#39;</span> <span class="ow">in</span> <span class="n">data_feed</span> <span class="ow">and</span> <span class="n">data_feed</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">]</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_feed</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">_device</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">is_optional</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">default</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;arg :</span><span class="si">{0}</span><span class="s1"> cannot mapping correctly!&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">arg</span><span class="p">))</span>
                <span class="c1"># print(&#39;arg_map&#39;,arg_map.key_list)</span>
                <span class="k">if</span> <span class="n">ctx</span><span class="o">.</span><span class="n">amp_available</span> <span class="o">==</span> <span class="kc">True</span> <span class="ow">and</span> <span class="n">is_autocast_enabled</span> <span class="o">==</span> <span class="kc">True</span> <span class="ow">and</span> <span class="n">get_device</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">():</span>
                        <span class="n">out</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">arg_map</span><span class="o">.</span><span class="n">value_list</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">arg_map</span><span class="o">.</span><span class="n">value_list</span><span class="p">)</span>
                    <span class="c1"># for item in data.value_list:</span>
                    <span class="c1">#     if hasattr(item, &#39;cpu&#39;):</span>
                    <span class="c1">#         item.cpu()</span>
                <span class="k">return</span> <span class="n">out</span>
            <span class="k">elif</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="s1">&#39;signature&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="s1">&#39;_signature&#39;</span><span class="p">))</span> <span class="ow">and</span> <span class="n">callable</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
                <span class="n">sig</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">_signature</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="s1">&#39;_signature&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">fn</span><span class="o">.</span><span class="n">signature</span>
                <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">fn</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">key_list</span><span class="p">:</span>
                    <span class="n">is_optional</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span><span class="o">.</span><span class="n">optional</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">arg</span><span class="p">],</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span>
                    <span class="n">default</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span><span class="o">.</span><span class="n">default</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">arg</span><span class="p">],</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
                    <span class="n">is_input</span> <span class="o">=</span> <span class="n">arg</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;input&#39;</span><span class="p">]</span>
                    <span class="n">is_output</span> <span class="o">=</span> <span class="n">arg</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;output&#39;</span><span class="p">,</span> <span class="s1">&#39;y_pred&#39;</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">data_feed</span> <span class="ow">and</span> <span class="n">data_feed</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_feed</span><span class="p">[</span><span class="n">arg</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">get_device</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">arg</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">get_device</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">is_input</span> <span class="ow">and</span> <span class="s1">&#39;input&#39;</span> <span class="ow">in</span> <span class="n">data_feed</span> <span class="ow">and</span> <span class="n">data_feed</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">]</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_feed</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">get_device</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">is_output</span> <span class="ow">and</span> <span class="s1">&#39;output&#39;</span> <span class="ow">in</span> <span class="n">data_feed</span> <span class="ow">and</span> <span class="n">data_feed</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">]</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_feed</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">get_device</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">partial</span><span class="p">)</span> <span class="ow">and</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">fn</span><span class="o">.</span><span class="n">keywords</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">keywords</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span>
                    <span class="k">elif</span> <span class="n">is_optional</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">default</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;arg :</span><span class="si">{0}</span><span class="s1"> cannot mapping correctly!&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">arg</span><span class="p">))</span>

                <span class="c1"># print(&#39;arg_map&#39;, arg_map.key_list)</span>
                <span class="k">if</span> <span class="n">ctx</span><span class="o">.</span><span class="n">amp_available</span> <span class="o">==</span> <span class="kc">True</span> <span class="ow">and</span> <span class="n">is_autocast_enabled</span> <span class="o">==</span> <span class="kc">True</span> <span class="ow">and</span> <span class="n">get_device</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">():</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">partial</span><span class="p">):</span>
                            <span class="n">out</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">arg_map</span><span class="o">.</span><span class="n">value_list</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">out</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">arg_map</span><span class="o">.</span><span class="n">value_list</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">partial</span><span class="p">):</span>
                        <span class="n">out</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">arg_map</span><span class="o">.</span><span class="n">value_list</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">out</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">arg_map</span><span class="o">.</span><span class="n">value_list</span><span class="p">)</span>
                    <span class="c1"># for item in data.value_list:</span>
                    <span class="c1">#     if hasattr(item, &#39;cpu&#39;):</span>
                    <span class="c1">#         item.cpu()</span>

                <span class="k">return</span> <span class="n">out</span>
            <span class="k">elif</span> <span class="n">callable</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
                <span class="n">fn</span><span class="o">.</span><span class="n">signature</span> <span class="o">=</span> <span class="n">get_signature</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
                <span class="n">args</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">key_list</span>
                <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
                    <span class="n">is_optional</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span><span class="o">.</span><span class="n">optional</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fn</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">arg</span><span class="p">],</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span>
                    <span class="n">default</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span><span class="o">.</span><span class="n">default</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fn</span><span class="o">.</span><span class="n">signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">arg</span><span class="p">],</span> <span class="n">TensorSpec</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>
                    <span class="n">is_input</span> <span class="o">=</span> <span class="n">arg</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;input&#39;</span><span class="p">]</span>
                    <span class="n">is_output</span> <span class="o">=</span> <span class="n">arg</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;output&#39;</span><span class="p">,</span> <span class="s1">&#39;y_pred&#39;</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">data_feed</span> <span class="ow">and</span> <span class="n">data_feed</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_feed</span><span class="p">[</span><span class="n">arg</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">get_device</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">arg</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">get_device</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">is_input</span> <span class="ow">and</span> <span class="s1">&#39;input&#39;</span> <span class="ow">in</span> <span class="n">data_feed</span> <span class="ow">and</span> <span class="n">data_feed</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">]</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_feed</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">get_device</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">is_output</span> <span class="ow">and</span> <span class="s1">&#39;output&#39;</span> <span class="ow">in</span> <span class="n">data_feed</span> <span class="ow">and</span> <span class="n">data_feed</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">]</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_feed</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">get_device</span><span class="p">())</span>
                    <span class="k">elif</span> <span class="n">is_optional</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">default</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">arg_map</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>
                <span class="c1"># print(&#39;arg_map&#39;, arg_map.key_list)</span>
                <span class="k">if</span> <span class="n">ctx</span><span class="o">.</span><span class="n">amp_available</span> <span class="o">==</span> <span class="kc">True</span> <span class="ow">and</span> <span class="n">is_autocast_enabled</span> <span class="o">==</span> <span class="kc">True</span> <span class="ow">and</span> <span class="n">get_device</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">():</span>
                        <span class="n">out</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">arg_map</span><span class="o">.</span><span class="n">value_list</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">out</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">arg_map</span><span class="o">.</span><span class="n">value_list</span><span class="p">)</span>
                    <span class="c1"># for item in data.value_list:</span>
                    <span class="c1">#     if is_tensor(item):</span>
                    <span class="c1">#         item.cpu()</span>
                <span class="k">return</span> <span class="n">out</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;uncomplete arg_map&#39;</span><span class="p">,</span> <span class="n">arg_map</span><span class="o">.</span><span class="n">key_list</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="n">PrintException</span><span class="p">()</span></div>


<span class="k">def</span> <span class="nf">force_deterministic</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Force most of the computation nodes to run deterministically.</span>

<span class="sd">    Args:</span>
<span class="sd">        seed (int): set the random seed for all random ops in the graph and readers.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;PYTHONHASHSEED&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>


<div class="viewcode-block" id="fix_layer"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.fix_layer">[docs]</a><span class="k">def</span> <span class="nf">fix_layer</span><span class="p">(</span><span class="n">layer</span><span class="p">:</span> <span class="n">Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;fix existing out-of-date model compatibility</span>

<span class="sd">    Args:</span>
<span class="sd">        layer (trident Layer):</span>

<span class="sd">    Returns: fixed layer</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;is_root&#39;</span><span class="p">):</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">is_root</span> <span class="o">=</span> <span class="kc">True</span>


    <span class="k">def</span> <span class="nf">get_root</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_nodes&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;is_root&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_root</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="s1">&#39;default_name&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">default_name</span> <span class="o">==</span> <span class="s2">&quot;sequential_1&quot;</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">node</span>
            <span class="k">return</span> <span class="bp">self</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;device&#39;</span><span class="p">):</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">device</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span>

    <span class="n">layer</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">get_device</span><span class="p">())</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;_nodes&#39;</span><span class="p">):</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">_nodes</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;_uid_prefixs&#39;</span><span class="p">):</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">_uid_prefixs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">reset_name</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">_uid_prefixs</span><span class="p">)</span>

    <span class="k">if</span> <span class="s1">&#39;ssd&#39;</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">__base__</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">or</span> <span class="s1">&#39;yolo&#39;</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">__base__</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;nms_threshold&#39;</span><span class="p">):</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;nms_threshold&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;detection_threshold&#39;</span><span class="p">):</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;detection_threshold&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">]):</span>
        <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">]</span>
        <span class="n">dims</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">item</span><span class="p">))</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">TensorShape</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">)])</span>
    <span class="k">elif</span> <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">is_tensor</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">):</span>
        <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">]</span>
        <span class="n">dims</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">buffers</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;_buffers&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">&#39;_input_shape&#39;</span> <span class="ow">in</span> <span class="n">buffers</span><span class="p">:</span>
            <span class="k">del</span> <span class="n">buffers</span><span class="p">[</span><span class="s1">&#39;_input_shape&#39;</span><span class="p">]</span>
        <span class="nb">object</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;_input_shape&#39;</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">(</span><span class="n">dims</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">):</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">)</span> <span class="ow">and</span> <span class="n">is_tensor</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span><span class="o">.</span><span class="n">dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">([</span><span class="n">d</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span><span class="o">.</span><span class="n">dims</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">]):</span>
        <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span><span class="p">]</span>
        <span class="n">dims</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">_input_shape</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">item</span><span class="p">))</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">TensorShape</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">)])</span>
    <span class="k">elif</span> <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">is_tensor</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">):</span>
        <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">]</span>
        <span class="n">dims</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">buffers</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;_buffers&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">&#39;_input_shape&#39;</span> <span class="ow">in</span> <span class="n">buffers</span><span class="p">:</span>
            <span class="k">del</span> <span class="n">buffers</span><span class="p">[</span><span class="s1">&#39;_output_shape&#39;</span><span class="p">]</span>
        <span class="nb">object</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;_output_shape&#39;</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">(</span><span class="n">dims</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">):</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="o">.</span><span class="n">dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span>
            <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="o">.</span><span class="n">dims</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="o">.</span><span class="n">dims</span><span class="p">])</span>
    <span class="k">elif</span> <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="o">.</span><span class="n">dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">):</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">d</span><span class="p">))</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">_output_shape</span><span class="o">.</span><span class="n">dims</span><span class="p">])</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;get_root&#39;</span><span class="p">):</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;get_root&#39;</span><span class="p">,</span> <span class="n">MethodType</span><span class="p">(</span><span class="n">get_root</span><span class="p">,</span> <span class="n">layer</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
        <span class="n">module</span><span class="o">.</span><span class="n">dump_patches</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="c1"># if not hasattr(module, &#39;_signature&#39;):</span>
        <span class="c1">#     module._signature = inspect.signature(module.forward)</span>
        <span class="n">class_name</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;get_root&#39;</span><span class="p">):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;get_root&#39;</span><span class="p">,</span> <span class="n">MethodType</span><span class="p">(</span><span class="n">get_root</span><span class="p">,</span> <span class="n">layer</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;uuid&#39;</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">uuid</span> <span class="o">=</span> <span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">()</span><span class="o">.</span><span class="n">node</span>
        <span class="c1"># check for root</span>
        <span class="k">if</span> <span class="n">module</span><span class="o">.</span><span class="n">uuid</span> <span class="o">==</span> <span class="n">layer</span><span class="o">.</span><span class="n">uuid</span><span class="p">:</span>
            <span class="n">module</span><span class="o">.</span><span class="n">is_root</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">module</span><span class="o">.</span><span class="n">is_root</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;relative_name&#39;</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">relative_name</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;_uid_prefixs&#39;</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">_uid_prefixs</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_root</span><span class="p">()</span><span class="o">.</span><span class="n">_uid_prefixs</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;default_name&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">default_name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">default_name</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">module_prefix</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
            <span class="n">module</span><span class="o">.</span><span class="n">default_name</span> <span class="o">=</span> <span class="n">camel2snake</span><span class="p">(</span><span class="n">module_prefix</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">get_global_uid</span><span class="p">(</span><span class="n">camel2snake</span><span class="p">(</span><span class="n">module_prefix</span><span class="p">)))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;_name&#39;</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">reset_name</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_root</span><span class="p">()</span><span class="o">.</span><span class="n">_uid_prefixs</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">_name</span> <span class="k">if</span> <span class="n">module</span><span class="o">.</span><span class="n">_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">_name</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">module</span><span class="o">.</span><span class="n">relative_name</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;_built&#39;</span><span class="p">):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;built&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;keepdim&#39;</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;keepdim&#39;</span><span class="p">)</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;keepdim&#39;</span><span class="p">)</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;keepdims&#39;</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;_non_persistent_buffers_set&#39;</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">_non_persistent_buffers_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

        <span class="c1"># fix for shape definition</span>
        <span class="c1"># if not isinstance(module._input_shape, TensorShape):</span>
        <span class="c1">#     module._input_shape = TensorShape(to_numpy(module._input_shape))</span>
        <span class="c1">#</span>
        <span class="c1"># if not isinstance(module._output_shape, TensorShape):</span>
        <span class="c1">#     module._output_shape = TensorShape(to_numpy(module._output_shape))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;batch_index&#39;</span><span class="p">):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;batch_index&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;filter_index&#39;</span><span class="p">):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;filter_index&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;in_sequence&#39;</span><span class="p">):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;in_sequence&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;in_sequence&#39;</span><span class="p">):</span>
            <span class="k">if</span> <span class="s1">&#39;lstm&#39;</span> <span class="ow">in</span> <span class="n">class_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">or</span> <span class="s1">&#39;gru&#39;</span> <span class="ow">in</span> <span class="n">class_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">or</span> <span class="s1">&#39;rnn&#39;</span> <span class="ow">in</span> <span class="n">class_name</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                <span class="n">module</span><span class="o">.</span><span class="n">in_sequence</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">module</span><span class="o">.</span><span class="n">in_sequence</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="s1">&#39;Conv&#39;</span> <span class="ow">in</span> <span class="n">class_name</span> <span class="ow">and</span> <span class="s1">&#39;Block&#39;</span> <span class="ow">in</span> <span class="n">class_name</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;sequence_rank&#39;</span><span class="p">):</span>
                <span class="n">module</span><span class="o">.</span><span class="n">sequence_rank</span> <span class="o">=</span> <span class="s1">&#39;cna&#39;</span>

        <span class="k">if</span> <span class="s1">&#39;Conv&#39;</span> <span class="ow">in</span> <span class="n">class_name</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;depth_multiplier&#39;</span><span class="p">):</span>
                <span class="k">if</span> <span class="s1">&#39;Depthwise&#39;</span> <span class="ow">in</span> <span class="n">class_name</span> <span class="ow">or</span> <span class="s1">&#39;Separable&#39;</span> <span class="ow">in</span> <span class="n">class_name</span><span class="p">:</span>
                    <span class="n">module</span><span class="o">.</span><span class="n">depth_multiplier</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">module</span><span class="o">.</span><span class="n">depth_multiplier</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;use_spectral&#39;</span><span class="p">):</span>
                <span class="n">module</span><span class="o">.</span><span class="n">use_spectral</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">is_root</span> <span class="o">==</span> <span class="kc">True</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;_signature&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">layer</span><span class="o">.</span><span class="n">_signature</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_signature</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">_signature</span> <span class="o">=</span> <span class="n">get_signature</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">layer</span></div>


<div class="viewcode-block" id="fix_pytorch_module"><a class="viewcode-back" href="../../../trident.backend.html#trident.backend.pytorch_backend.fix_pytorch_module">[docs]</a><span class="k">def</span> <span class="nf">fix_pytorch_module</span><span class="p">(</span><span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">:</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="n">TensorShape</span><span class="p">)</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="n">module</span><span class="o">.</span><span class="n">is_root</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">module</span><span class="o">.</span><span class="n">name</span><span class="o">=</span><span class="n">module</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
    <span class="n">module</span><span class="o">.</span><span class="n">_nodes</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
    <span class="n">module</span><span class="o">.</span><span class="n">_uid_prefixs</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">module</span><span class="o">.</span><span class="n">_signature</span> <span class="o">=</span> <span class="n">get_signature</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
    <span class="n">module</span><span class="o">.</span><span class="n">signature</span> <span class="o">=</span> <span class="n">get_signature</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getweights</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">get_uid</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
        <span class="n">module</span><span class="o">.</span><span class="n">_uid_prefixs</span><span class="p">[</span><span class="n">prefix</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">module</span><span class="o">.</span><span class="n">_uid_prefixs</span><span class="p">[</span><span class="n">prefix</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">get_root</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;_nodes&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">module</span><span class="o">.</span><span class="n">_nodes</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">_nodes</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">module</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;is_root&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_root</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">_nodes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="s1">&#39;default_name&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">default_name</span> <span class="o">==</span> <span class="s2">&quot;sequential_1&quot;</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">node</span>
            <span class="k">return</span> <span class="n">module</span>


    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">mod</span> <span class="o">!=</span> <span class="n">module</span><span class="p">:</span>
            <span class="n">module</span><span class="o">.</span><span class="n">is_root</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">mod</span><span class="o">.</span><span class="n">_built</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span><span class="s1">&#39;built&#39;</span><span class="p">):</span>
            <span class="n">mod</span><span class="o">.</span><span class="n">built</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">mod</span><span class="o">.</span><span class="n">relative_name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="n">mod</span><span class="o">.</span><span class="n">batch_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">mod</span><span class="o">.</span><span class="n">filter_index</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="n">mod</span><span class="o">.</span><span class="n">in_sequence</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">mod</span><span class="o">.</span><span class="n">uuid</span> <span class="o">=</span> <span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">()</span><span class="o">.</span><span class="n">node</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="n">mod</span><span class="o">.</span><span class="n">default_name</span> <span class="o">=</span> <span class="n">camel2snake</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">get_uid</span><span class="p">(</span><span class="n">camel2snake</span><span class="p">(</span><span class="n">prefix</span><span class="p">)))</span>

        <span class="n">mod</span><span class="o">.</span><span class="n">_input_shape</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">mod</span><span class="o">.</span><span class="n">_output_shape</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">mod</span><span class="o">.</span><span class="n">keep_output</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">mod</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;_output_tensor&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">mod</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">get_device</span><span class="p">()</span>
        <span class="c1">#mod._signature = inspect.signature(mod.forward)</span>
        <span class="n">mod</span><span class="o">.</span><span class="n">dump_patches</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="c1">#</span>
        <span class="c1"># def getsignature(mod):</span>
        <span class="c1">#     return mod._signature</span>
        <span class="c1">#</span>
        <span class="c1"># def setsignature(mod, value):</span>
        <span class="c1">#     mod._signature = value</span>
        <span class="c1">#</span>
        <span class="c1"># def delsignature(mod):</span>
        <span class="c1">#     del mod._signature</span>
        <span class="c1">#</span>
        <span class="c1"># mod.signature= property(getsignature, setsignature, delsignature, &quot;signature&quot;)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="s1">&#39;get_root&#39;</span><span class="p">):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="s1">&#39;get_root&#39;</span><span class="p">,</span> <span class="n">MethodType</span><span class="p">(</span><span class="n">get_root</span><span class="p">,</span> <span class="n">mod</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="s1">&#39;weights&#39;</span><span class="p">):</span>
            <span class="bp">cls</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="nb">property</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="s1">&#39;dims&#39;</span><span class="p">):</span>
            <span class="n">mod</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">dims</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;keepdim&#39;</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;keepdim&#39;</span><span class="p">)</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;keepdims&#39;</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

    <span class="c1"># def register_hook(module):</span>
    <span class="c1">#     def hook(module, input, output):</span>
    <span class="c1">#         # class_name =module.re    module.name   # str(module.__class__).split(&quot;.&quot;)[-1].split(&quot;&#39;&quot;)[0]</span>
    <span class="c1">#         input = iteration_tools.flatten([input], iterable_types=(list, tuple))</span>
    <span class="c1">#         input = unpack_singleton([item for item in input if item is not None])</span>
    <span class="c1">#</span>
    <span class="c1">#         if isinstance(input, (list, tuple)):</span>
    <span class="c1">#             module._input_shape = tuple([tensor_to_shape(t, need_exclude_batch_axis=True, is_singleton=False) for t in input])</span>
    <span class="c1">#             module.input_shape = module._input_shape</span>
    <span class="c1">#         elif is_tensor(input):</span>
    <span class="c1">#             module._input_shape = tensor_to_shape(input, need_exclude_batch_axis=True, is_singleton=False)</span>
    <span class="c1">#             module.input_shape = module._input_shape</span>
    <span class="c1">#</span>
    <span class="c1">#         output = iteration_tools.flatten([output], iterable_types=(list, tuple))</span>
    <span class="c1">#         output = unpack_singleton([item for item in output if item is not None])</span>
    <span class="c1">#         if isinstance(output, (list, tuple)):</span>
    <span class="c1">#             module._output_shape = tuple([tensor_to_shape(t, need_exclude_batch_axis=True, is_singleton=False) for t in output])</span>
    <span class="c1">#             module.output_shape = module._output_shape</span>
    <span class="c1">#         elif is_tensor(output):</span>
    <span class="c1">#             module._output_shape = tensor_to_shape(output, need_exclude_batch_axis=True, is_singleton=False)</span>
    <span class="c1">#             module.output_shape = module._output_shape</span>
    <span class="c1">#</span>
    <span class="c1">#         hooks.append(module.register_forward_hook(hook))</span>
    <span class="c1">#</span>
    <span class="c1"># hooks = []</span>
    <span class="c1">#</span>
    <span class="c1"># # register hook</span>
    <span class="c1"># module.apply(register_hook)</span>
    <span class="c1">#</span>
    <span class="c1"># if module.signature is not None:</span>
    <span class="c1">#     input_tensor = [to_tensor(module.signature.inputs.value_list[k].get_dummy_tensor()) for k in  range(module.signature.inputs.value_list) if not module.signature.inputs.value_list[k].optional or k==0]</span>
    <span class="c1">#     # make a forward pass</span>
    <span class="c1">#     # print(x.shape)</span>
    <span class="c1">#     module(*input_tensor)</span>
    <span class="c1">#</span>
    <span class="c1"># # remove these hooks</span>
    <span class="c1"># for h in hooks:</span>
    <span class="c1">#     h.remove()</span>
    <span class="k">return</span> <span class="n">module</span></div>
</pre></div>

        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
  </div>
        <footer class="mdl-mini-footer">
    <div class="mdl-mini-footer__left-section">
      <div class="mdl-logo">trident</div>
      <div>
        
        
      </div>
    </div>

    <div class="mdl-mini-footer__right-section">
        <div>&copy; Copyright 2022, AllanYiin.</div>
      <div>Generated by <a href="http://sphinx.pocoo.org/">Sphinx</a> 5.0.2 using <a href="https://github.com/myyasuda/sphinx_materialdesign_theme">sphinx_materialdesign_theme</a>.</div>
    </div>
</footer>
        </main>
    </div>
  </body>
</html>